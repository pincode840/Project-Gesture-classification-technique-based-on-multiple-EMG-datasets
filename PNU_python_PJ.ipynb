{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "688ab5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9059e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ninapro 데이터셋 불러오기\n",
    "ninapro_df = pd.DataFrame()\n",
    "for i in range (1,11):\n",
    "    adress = f\"ninapro_db5/ninapro_db_{i}/S{i}_E2_A1\"\n",
    "    filename = adress\n",
    "    mat = sio.loadmat(filename)\n",
    "    emg = mat['emg']\n",
    "    Restimulus = mat['restimulus']\n",
    "    rerepetition = mat['rerepetition']\n",
    "    df_emg = pd.DataFrame(emg)\n",
    "    df_Restimulus = pd.DataFrame(Restimulus)\n",
    "#    df_rerepetition = pd.DataFrame(rerepetition)\n",
    "    df = pd.concat([df_emg, df_Restimulus], axis=1)\n",
    "#    df = pd.concat([df, df_rerepetition], axis=1)\n",
    "#    df.columns = ['emg1', 'emg2', 'emg3', 'emg4', 'emg5', 'emg6', 'emg7', 'emg8', 'emg9', 'emg10', 'emg11', 'emg12', 'emg13', 'emg14', 'emg15', 'emg16', 'Restimulus', 'rerepetition']\n",
    "    df.columns = ['emg1', 'emg2', 'emg3', 'emg4', 'emg5', 'emg6', 'emg7', 'emg8', 'emg9', 'emg10', 'emg11', 'emg12', 'emg13', 'emg14', 'emg15', 'emg16', 'Restimulus']\n",
    "    ninapro_df = pd.concat([ninapro_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1d8918c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "설정 확인: 200Hz -> 1000Hz 변환 (비율: 5.0배)\n",
      "데이터 변환 진행 중 (Splitting -> Upsampling -> Normalization)...\n",
      "------------------------------\n",
      "변환 완료!\n",
      "총 샘플(동작) 개수: 1020\n",
      "최대 시퀀스 길이 (Max Time Steps): 7245\n",
      "입력 데이터 Shape (X): (1020, 7245, 16)\n",
      "라벨 데이터 Shape (y): (1020,)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#upsampling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess_emg_data(df):\n",
    "   \n",
    "    # 설정 값\n",
    "    ORIGINAL_FS = 200   # 기존 주파수\n",
    "    TARGET_FS = 1000    # 목표 주파수\n",
    "    RESAMPLE_RATIO = TARGET_FS / ORIGINAL_FS # 5.0\n",
    "\n",
    "    # 1. 데이터와 라벨 분리\n",
    "    # 마지막 컬럼이 Restimulus라고 가정\n",
    "    feature_cols = df.columns[:-1]  # EMG 채널 16개\n",
    "    label_col = df.columns[-1]      # Restimulus\n",
    "    \n",
    "    print(f\"설정 확인: {ORIGINAL_FS}Hz -> {TARGET_FS}Hz 변환 (비율: {RESAMPLE_RATIO}배)\")\n",
    "    \n",
    "    # 2. 동작(Class)별 구간 자르기\n",
    "    # 단순히 라벨값(0,1,2..)으로 묶는게 아니라, 시간 순서상 '연속된 동작' 단위로 잘라야 함\n",
    "    # 라벨이 변하는 지점마다 새로운 그룹 ID 부여\n",
    "    df['segment_id'] = (df[label_col] != df[label_col].shift()).cumsum()\n",
    "    \n",
    "    processed_data_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    # 그룹별 처리\n",
    "    print(\"데이터 변환 진행 중 (Splitting -> Upsampling -> Normalization)...\")\n",
    "    \n",
    "    for _, group in df.groupby('segment_id'):\n",
    "        # 현재 구간의 라벨\n",
    "        current_label = group[label_col].iloc[0]\n",
    "        \n",
    "        # (선택사항) 0번 클래스(Rest/휴식)가 학습에 불필요하다면 아래 주석 해제하여 건너뛰기\n",
    "        if current_label == 0: continue\n",
    "        \n",
    "        # 해당 구간의 EMG 데이터 추출 (Numpy 변환)\n",
    "        raw_signal = group[feature_cols].values\n",
    "        \n",
    "        # 3. 1000Hz Upsampling\n",
    "        # 변환 후 샘플 수 계산: 현재 길이 * 5\n",
    "        new_length = int(len(raw_signal) * RESAMPLE_RATIO)\n",
    "        \n",
    "        if new_length > 0:\n",
    "            # Fourier method를 이용한 리샘플링 (신호 손실 최소화)\n",
    "            upsampled_signal = signal.resample(raw_signal, new_length)\n",
    "            \n",
    "            # 4. Z-score 정규화 (Standardization)\n",
    "            # 각 동작 구간(Segment)마다 독립적으로 정규화 수행\n",
    "            scaler = StandardScaler()\n",
    "            normalized_signal = scaler.fit_transform(upsampled_signal)\n",
    "            \n",
    "            processed_data_list.append(normalized_signal)\n",
    "            labels_list.append(current_label)\n",
    "            \n",
    "    # 5. 모델 입력을 위한 Padding 및 Numpy Stacking\n",
    "    # 모델에 넣으려면 모든 데이터의 Time Step(길이)이 같아야 함.\n",
    "    # 가장 긴 데이터를 기준으로 나머지는 0으로 채움 (Zero-padding)\n",
    "    \n",
    "    max_seq_len = max(len(d) for d in processed_data_list)\n",
    "    num_samples = len(processed_data_list)\n",
    "    num_channels = len(feature_cols) # 16\n",
    "    \n",
    "    # 결과 담을 빈 배열 생성 (Batch, Time, Channel)\n",
    "    X_padded = np.zeros((num_samples, max_seq_len, num_channels))\n",
    "    \n",
    "    # 데이터 채워넣기\n",
    "    for i, data in enumerate(processed_data_list):\n",
    "        length = len(data)\n",
    "        X_padded[i, :length, :] = data  # 앞쪽부터 데이터 채움 (Post-padding 0)\n",
    "        \n",
    "    y_labels = np.array(labels_list)\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(\"변환 완료!\")\n",
    "    print(f\"총 샘플(동작) 개수: {num_samples}\")\n",
    "    print(f\"최대 시퀀스 길이 (Max Time Steps): {max_seq_len}\")\n",
    "    print(f\"입력 데이터 Shape (X): {X_padded.shape}\") # (Batch, Time, 16)\n",
    "    print(f\"라벨 데이터 Shape (y): {y_labels.shape}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    return X_padded, y_labels\n",
    "\n",
    "\n",
    "X_up, y_up = preprocess_emg_data(ninapro_df)\n",
    "\n",
    "# 3. 모델 입력 확인\n",
    "# 1D CNN + Attention 모델에 입력으로 'X'를, 타겟으로 'y'를 사용하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86cd14ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nature_df1110 종료\n",
      "nature_df1111 종료\n",
      "nature_df1112 종료\n",
      "nature_df1113 종료\n",
      "nature_df1114 종료\n",
      "nature_df1115 종료\n",
      "nature_df1116 종료\n",
      "nature_df1117 종료\n",
      "nature_df1118 종료\n",
      "nature_df1119 종료\n",
      "nature_df11110 종료\n",
      "nature_df11111 종료\n",
      "nature_df11112 종료\n",
      "nature_df11113 종료\n",
      "nature_df11114 종료\n",
      "nature_df11115 종료\n",
      "nature_df11116 종료\n",
      "nature_df11117 종료\n",
      "nature_df11118 종료\n",
      "nature_df11119 종료\n",
      "nature_df11120 종료\n",
      "nature_df11121 종료\n",
      "nature_df11122 종료\n",
      "nature_df11123 종료\n",
      "nature_df11124 종료\n",
      "nature_df11125 종료\n",
      "nature_df11126 종료\n",
      "nature_df11127 종료\n",
      "nature_df11128 종료\n",
      "nature_df11129 종료\n",
      "nature_df11130 종료\n",
      "nature_df11131 종료\n",
      "nature_df11132 종료\n",
      "nature_df11133 종료\n",
      "nature_df11134 종료\n",
      "nature_df11135 종료\n",
      "nature_df11136 종료\n",
      "nature_df11137 종료\n",
      "nature_df11138 종료\n",
      "nature_df11139 종료\n",
      "nature_df11140 종료\n",
      "nature_df11141 종료\n",
      "nature_df11142 종료\n",
      "nature_df11143 종료\n",
      "nature_df11144 종료\n",
      "nature_df11145 종료\n",
      "nature_df11146 종료\n",
      "nature_df11147 종료\n",
      "nature_df11148 종료\n",
      "nature_df11149 종료\n",
      "nature_df11150 종료\n",
      "nature_df11151 종료\n",
      "nature_df11152 종료\n",
      "nature_df11153 종료\n",
      "nature_df11154 종료\n",
      "nature_df11155 종료\n",
      "nature_df11156 종료\n",
      "nature_df11157 종료\n",
      "nature_df11158 종료\n",
      "nature_df11159 종료\n",
      "nature_df11160 종료\n",
      "nature_df11161 종료\n",
      "nature_df11162 종료\n",
      "nature_df11163 종료\n",
      "nature_df11164 종료\n",
      "nature_df11165 종료\n",
      "nature_df11166 종료\n",
      "nature_df11167 종료\n",
      "nature_df11168 종료\n",
      "nature_df11169 종료\n",
      "nature_df11170 종료\n",
      "nature_df11171 종료\n",
      "nature_df11172 종료\n",
      "nature_df11173 종료\n",
      "nature_df11174 종료\n",
      "nature_df11175 종료\n",
      "nature_df11176 종료\n",
      "nature_df11177 종료\n",
      "nature_df11178 종료\n",
      "nature_df11179 종료\n",
      "nature_df11180 종료\n",
      "nature_df11181 종료\n",
      "nature_df11182 종료\n",
      "nature_df11183 종료\n",
      "nature_df11184 종료\n",
      "nature_df11185 종료\n",
      "nature_df11186 종료\n",
      "nature_df11187 종료\n",
      "nature_df11188 종료\n",
      "nature_df11189 종료\n",
      "nature_df11190 종료\n",
      "nature_df11191 종료\n",
      "nature_df11192 종료\n",
      "nature_df11193 종료\n",
      "nature_df11194 종료\n",
      "nature_df11195 종료\n",
      "nature_df11196 종료\n",
      "nature_df11197 종료\n",
      "nature_df11198 종료\n",
      "nature_df11199 종료\n",
      "nature_df111100 종료\n",
      "nature_df111101 종료\n",
      "nature_df111102 종료\n",
      "nature_df111103 종료\n",
      "nature_df111104 종료\n",
      "nature_df111105 종료\n",
      "nature_df111106 종료\n",
      "nature_df111107 종료\n",
      "nature_df111108 종료\n",
      "nature_df111109 종료\n",
      "nature_df111110 종료\n",
      "nature_df111111 종료\n",
      "nature_df111112 종료\n",
      "nature_df111113 종료\n",
      "nature_df111114 종료\n",
      "nature_df111115 종료\n",
      "nature_df111116 종료\n",
      "nature_df111117 종료\n",
      "nature_df111118 종료\n",
      "nature_df111119 종료\n",
      "nature_df111120 종료\n",
      "nature_df111121 종료\n",
      "nature_df111122 종료\n",
      "nature_df111123 종료\n",
      "nature_df111124 종료\n",
      "nature_df111125 종료\n",
      "nature_df111126 종료\n",
      "nature_df111127 종료\n",
      "nature_df111128 종료\n",
      "nature_df111129 종료\n",
      "nature_df111130 종료\n",
      "nature_df111131 종료\n",
      "nature_df111132 종료\n",
      "nature_df111133 종료\n",
      "nature_df111134 종료\n",
      "nature_df111135 종료\n",
      "nature_df111136 종료\n",
      "nature_df111137 종료\n",
      "nature_df111138 종료\n",
      "nature_df111139 종료\n",
      "nature_df111140 종료\n",
      "nature_df111141 종료\n",
      "nature_df111142 종료\n",
      "nature_df111143 종료\n",
      "nature_df111144 종료\n",
      "nature_df111145 종료\n",
      "nature_df111146 종료\n",
      "nature_df111147 종료\n",
      "nature_df111148 종료\n",
      "nature_df111149 종료\n",
      "nature_df1120 종료\n",
      "nature_df1121 종료\n",
      "nature_df1122 종료\n",
      "nature_df1123 종료\n",
      "nature_df1124 종료\n",
      "nature_df1125 종료\n",
      "nature_df1126 종료\n",
      "nature_df1127 종료\n",
      "nature_df1128 종료\n",
      "nature_df1129 종료\n",
      "nature_df11210 종료\n",
      "nature_df11211 종료\n",
      "nature_df11212 종료\n",
      "nature_df11213 종료\n",
      "nature_df11214 종료\n",
      "nature_df11215 종료\n",
      "nature_df11216 종료\n",
      "nature_df11217 종료\n",
      "nature_df11218 종료\n",
      "nature_df11219 종료\n",
      "nature_df11220 종료\n",
      "nature_df11221 종료\n",
      "nature_df11222 종료\n",
      "nature_df11223 종료\n",
      "nature_df11224 종료\n",
      "nature_df11225 종료\n",
      "nature_df11226 종료\n",
      "nature_df11227 종료\n",
      "nature_df11228 종료\n",
      "nature_df11229 종료\n",
      "nature_df11230 종료\n",
      "nature_df11231 종료\n",
      "nature_df11232 종료\n",
      "nature_df11233 종료\n",
      "nature_df11234 종료\n",
      "nature_df11235 종료\n",
      "nature_df11236 종료\n",
      "nature_df11237 종료\n",
      "nature_df11238 종료\n",
      "nature_df11239 종료\n",
      "nature_df11240 종료\n",
      "nature_df11241 종료\n",
      "nature_df11242 종료\n",
      "nature_df11243 종료\n",
      "nature_df11244 종료\n",
      "nature_df11245 종료\n",
      "nature_df11246 종료\n",
      "nature_df11247 종료\n",
      "nature_df11248 종료\n",
      "nature_df11249 종료\n",
      "nature_df11250 종료\n",
      "nature_df11251 종료\n",
      "nature_df11252 종료\n",
      "nature_df11253 종료\n",
      "nature_df11254 종료\n",
      "nature_df11255 종료\n",
      "nature_df11256 종료\n",
      "nature_df11257 종료\n",
      "nature_df11258 종료\n",
      "nature_df11259 종료\n",
      "nature_df11260 종료\n",
      "nature_df11261 종료\n",
      "nature_df11262 종료\n",
      "nature_df11263 종료\n",
      "nature_df11264 종료\n",
      "nature_df11265 종료\n",
      "nature_df11266 종료\n",
      "nature_df11267 종료\n",
      "nature_df11268 종료\n",
      "nature_df11269 종료\n",
      "nature_df11270 종료\n",
      "nature_df11271 종료\n",
      "nature_df11272 종료\n",
      "nature_df11273 종료\n",
      "nature_df11274 종료\n",
      "nature_df11275 종료\n",
      "nature_df11276 종료\n",
      "nature_df11277 종료\n",
      "nature_df11278 종료\n",
      "nature_df11279 종료\n",
      "nature_df11280 종료\n",
      "nature_df11281 종료\n",
      "nature_df11282 종료\n",
      "nature_df11283 종료\n",
      "nature_df11284 종료\n",
      "nature_df11285 종료\n",
      "nature_df11286 종료\n",
      "nature_df11287 종료\n",
      "nature_df11288 종료\n",
      "nature_df11289 종료\n",
      "nature_df11290 종료\n",
      "nature_df11291 종료\n",
      "nature_df11292 종료\n",
      "nature_df11293 종료\n",
      "nature_df11294 종료\n",
      "nature_df11295 종료\n",
      "nature_df11296 종료\n",
      "nature_df11297 종료\n",
      "nature_df11298 종료\n",
      "nature_df11299 종료\n",
      "nature_df112100 종료\n",
      "nature_df112101 종료\n",
      "nature_df112102 종료\n",
      "nature_df112103 종료\n",
      "nature_df112104 종료\n",
      "nature_df112105 종료\n",
      "nature_df112106 종료\n",
      "nature_df112107 종료\n",
      "nature_df112108 종료\n",
      "nature_df112109 종료\n",
      "nature_df112110 종료\n",
      "nature_df112111 종료\n",
      "nature_df112112 종료\n",
      "nature_df112113 종료\n",
      "nature_df112114 종료\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m data_parame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrasp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_parame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrasp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(grasp_mapping)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m150\u001b[39m):\n\u001b[1;32m---> 20\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnature_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43ml\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     21\u001b[0m     df\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[0;32m     22\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRestimulus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dlrmflf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\dataset.py:1144\u001b[0m, in \u001b[0;36mDataset.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   1140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1141\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset.__array__ received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcopy\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut memory allocation cannot be avoided on read\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1143\u001b[0m     )\n\u001b[1;32m-> 1144\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;66;03m# Special case for (0,)*-shape datasets\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#nature 데이터셋 불러오기\n",
    "grasp_mapping = {\n",
    "    1: 6,\n",
    "    2: 18,\n",
    "    3: 7,\n",
    "    4: 5,\n",
    "    5: 19,\n",
    "    6: 0\n",
    "}\n",
    "\n",
    "nature_df = pd.DataFrame()\n",
    "for i in range(1, 9):\n",
    "    for j in range(1,3):\n",
    "        for k in range(1,3):\n",
    "            filename = fr'nature_data\\data\\participant_{i}\\participant{i}_day{j}_block{k}\\emg_data.hdf5'\n",
    "            data_parame = pd.read_csv(fr'nature_data\\data\\participant_{i}\\participant{i}_day{j}_block{k}\\trials.csv') \n",
    "            nature_data = h5py.File(filename, 'r')\n",
    "            data_parame['grasp'] = data_parame['grasp'].replace(grasp_mapping)\n",
    "            for l in range(0, 150):\n",
    "                df = pd.DataFrame(np.array(nature_data[f\"{l}\"]))\n",
    "                df=df.transpose()\n",
    "                df['Restimulus'] = ''\n",
    "                df['Restimulus'] = data_parame['grasp'].iloc[l]\n",
    "                nature_df = pd.concat([nature_df, df], axis=0)\n",
    "                print(f\"nature_df{i}{j}{k}{l} 종료\")\n",
    "nature_df.columns = ['emg1', 'emg2', 'emg3', 'emg4', 'emg5', 'emg6', 'emg7', 'emg8', 'emg9', 'emg10', 'emg11', 'emg12', 'emg13', 'emg14', 'emg15', 'emg16', 'Restimulus']\n",
    "#nature_df.to_csv('nature_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e06b70f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "11",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "12",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "13",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "14",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "15",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Restimulus",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "bfe641da-b4dc-46b6-a4f1-de04dec34907",
       "rows": [
        [
         "0",
         "3.763498e-05",
         "2.4820081e-05",
         "7.703583e-06",
         "8.394901e-06",
         "-1.6433607e-05",
         "-1.6854447e-06",
         "-5.0224203e-06",
         "-1.0069972e-05",
         "1.7126942e-05",
         "6.147569e-05",
         "-8.404105e-06",
         "-7.683242e-06",
         "-2.2499047e-05",
         "-8.373838e-06",
         "-1.5795224e-05",
         "-1.3093675e-05",
         "7"
        ],
        [
         "1",
         "1.9842508e-05",
         "2.6200492e-05",
         "9.893e-06",
         "7.721386e-06",
         "-1.6947637e-05",
         "-1.5601315e-06",
         "-8.243137e-06",
         "-6.803054e-06",
         "1.4402639e-05",
         "4.3410964e-05",
         "-1.1426932e-05",
         "-8.613109e-06",
         "-2.1518717e-05",
         "-1.2459999e-05",
         "-1.6132028e-05",
         "-1.7659913e-05",
         "7"
        ],
        [
         "2",
         "9.071698e-06",
         "2.5797071e-05",
         "1.0767478e-05",
         "7.572158e-06",
         "-2.4275832e-05",
         "-4.3219047e-06",
         "-1.3146786e-05",
         "-4.768144e-06",
         "1.3872751e-05",
         "2.4775052e-05",
         "-1.4892585e-05",
         "-1.05509025e-05",
         "-1.8330667e-05",
         "-1.2827803e-05",
         "-1.2900556e-05",
         "-1.6140055e-05",
         "7"
        ],
        [
         "3",
         "1.1730655e-05",
         "2.3411272e-05",
         "9.083008e-06",
         "6.6057505e-06",
         "-4.0930496e-05",
         "-9.383638e-06",
         "-1.6455762e-05",
         "-5.5978817e-06",
         "1.1760973e-05",
         "1.0308805e-05",
         "-1.6655787e-05",
         "-1.2232544e-05",
         "-1.4434503e-05",
         "-1.3317341e-05",
         "-8.378868e-06",
         "-1.2855331e-05",
         "7"
        ],
        [
         "4",
         "2.0980611e-05",
         "1.9648118e-05",
         "6.073029e-06",
         "4.666759e-06",
         "-4.3580178e-05",
         "-1.4690288e-05",
         "-1.837435e-05",
         "-8.043725e-06",
         "7.28028e-06",
         "2.6284695e-06",
         "-1.6393007e-05",
         "-1.1418758e-05",
         "-1.21324865e-05",
         "-1.4057723e-05",
         "-5.731359e-06",
         "-1.22871315e-05",
         "7"
        ],
        [
         "5",
         "2.5476582e-05",
         "1.6322627e-05",
         "3.857862e-06",
         "4.1010094e-06",
         "-1.4949009e-05",
         "-1.7673723e-05",
         "-1.8403234e-05",
         "-1.1598777e-05",
         "2.4376093e-06",
         "2.593578e-06",
         "-1.4498978e-05",
         "-1.1111728e-05",
         "-1.19266715e-05",
         "-1.4066295e-05",
         "-6.0540133e-06",
         "-1.5227999e-05",
         "7"
        ],
        [
         "6",
         "1.6708273e-05",
         "1.41972905e-05",
         "3.6773847e-06",
         "4.6992986e-06",
         "2.5450963e-05",
         "-1.7686485e-05",
         "-1.7334332e-05",
         "-1.5316356e-05",
         "-3.6807344e-06",
         "1.8110921e-06",
         "-1.3777299e-05",
         "-1.1044519e-05",
         "-1.1870927e-05",
         "-1.2869128e-05",
         "-5.956984e-06",
         "-1.6917604e-05",
         "7"
        ],
        [
         "7",
         "4.4182767e-07",
         "1.6379647e-05",
         "4.7480326e-06",
         "3.920168e-06",
         "5.5478373e-05",
         "-1.771093e-05",
         "-1.8691773e-05",
         "-1.853875e-05",
         "-9.87095e-06",
         "-4.730956e-06",
         "-1.5310217e-05",
         "-1.1111436e-05",
         "-1.2520413e-05",
         "-1.1641869e-05",
         "-4.121466e-06",
         "-1.3978675e-05",
         "7"
        ],
        [
         "8",
         "-7.496291e-06",
         "1.9489984e-05",
         "7.1035847e-06",
         "3.3927538e-06",
         "7.1499155e-05",
         "-1.8986877e-05",
         "-1.8534078e-05",
         "-1.8537225e-05",
         "-1.376124e-05",
         "-1.5292935e-05",
         "-1.8173328e-05",
         "-1.2233515e-05",
         "-1.544253e-05",
         "-1.1113223e-05",
         "-2.5244956e-06",
         "-1.0132854e-05",
         "7"
        ],
        [
         "9",
         "3.980215e-06",
         "2.2163e-05",
         "8.742185e-06",
         "2.3556913e-06",
         "7.150843e-05",
         "-1.913295e-05",
         "-1.8467656e-05",
         "-1.7795923e-05",
         "-1.5771924e-05",
         "-2.2833927e-05",
         "-2.045987e-05",
         "-1.379549e-05",
         "-1.7781957e-05",
         "-9.074342e-06",
         "-2.9938985e-06",
         "-7.0377127e-06",
         "7"
        ],
        [
         "10",
         "2.0346739e-05",
         "2.1517735e-05",
         "1.04601095e-05",
         "3.8299936e-06",
         "4.6536272e-05",
         "-1.7650784e-05",
         "-2.0613716e-05",
         "-1.633934e-05",
         "-1.8161161e-05",
         "-2.2709652e-05",
         "-1.9009383e-05",
         "-1.3657632e-05",
         "-1.8247843e-05",
         "-5.2644573e-06",
         "-2.9742137e-06",
         "-2.9753837e-06",
         "7"
        ],
        [
         "11",
         "2.736826e-05",
         "1.8554481e-05",
         "1.0799481e-05",
         "5.488192e-06",
         "5.3304293e-06",
         "-1.5703246e-05",
         "-2.1382793e-05",
         "-1.1357677e-05",
         "-1.772305e-05",
         "-1.7520932e-05",
         "-1.6881717e-05",
         "-8.891191e-06",
         "-1.5853977e-05",
         "-7.9643394e-07",
         "-2.4735623e-06",
         "6.4799275e-07",
         "7"
        ],
        [
         "12",
         "2.4527513e-05",
         "1.554986e-05",
         "8.60538e-06",
         "7.7068025e-06",
         "-4.4291497e-05",
         "-1.187706e-05",
         "-1.8465375e-05",
         "-4.151259e-06",
         "-1.3885709e-05",
         "-1.0185602e-05",
         "-1.2008449e-05",
         "-1.4340345e-06",
         "-1.377069e-05",
         "2.7958658e-06",
         "-3.7131615e-06",
         "9.917451e-07",
         "7"
        ],
        [
         "13",
         "1.504922e-05",
         "1.2883587e-05",
         "5.5067417e-06",
         "8.923973e-06",
         "-8.645796e-05",
         "-7.759527e-06",
         "-1.5192537e-05",
         "2.408472e-06",
         "-9.482013e-06",
         "-8.248469e-06",
         "-7.183376e-06",
         "2.3137409e-06",
         "-1.4945282e-05",
         "1.9076108e-06",
         "-7.387048e-06",
         "-1.6522204e-06",
         "7"
        ],
        [
         "14",
         "4.427592e-06",
         "1.0253072e-05",
         "4.3451e-06",
         "8.162445e-06",
         "-0.00010474059",
         "-3.4852933e-06",
         "-1.5541034e-05",
         "5.4122625e-06",
         "-6.6803473e-06",
         "-1.41816045e-05",
         "-5.3569333e-06",
         "2.014409e-06",
         "-2.0355492e-05",
         "-4.0465698e-06",
         "-1.3773081e-05",
         "-5.6050794e-06",
         "7"
        ],
        [
         "15",
         "-8.9958803e-07",
         "7.290047e-06",
         "4.3829773e-06",
         "6.614679e-06",
         "-0.00010822719",
         "-3.3219584e-07",
         "-1.8241566e-05",
         "5.7018224e-06",
         "-8.827494e-06",
         "-2.2264505e-05",
         "-4.122218e-06",
         "-1.4069668e-07",
         "-2.7730957e-05",
         "-8.839499e-06",
         "-1.999499e-05",
         "-9.819691e-06",
         "7"
        ],
        [
         "16",
         "-2.1909846e-06",
         "4.545228e-06",
         "3.825208e-06",
         "4.2121037e-06",
         "-0.00010892951",
         "1.8896407e-06",
         "-2.2769607e-05",
         "6.2320223e-06",
         "-1.5019026e-05",
         "-2.918083e-05",
         "-3.1924371e-06",
         "-1.4948188e-06",
         "-3.300888e-05",
         "-8.692068e-06",
         "-2.496824e-05",
         "-1.1360373e-05",
         "7"
        ],
        [
         "17",
         "-3.2504565e-06",
         "4.3330197e-06",
         "2.52119e-06",
         "1.914529e-06",
         "-9.96149e-05",
         "5.6295894e-06",
         "-2.622824e-05",
         "9.346426e-06",
         "-1.9427893e-05",
         "-3.7105776e-05",
         "-4.188752e-06",
         "-1.4150266e-06",
         "-3.6577898e-05",
         "-7.203739e-06",
         "-2.731646e-05",
         "-1.1095147e-05",
         "7"
        ],
        [
         "18",
         "-2.0139e-06",
         "6.697984e-06",
         "2.9971425e-06",
         "9.98576e-07",
         "-7.356327e-05",
         "9.721128e-06",
         "-2.183199e-05",
         "1.1755493e-05",
         "-1.981002e-05",
         "-4.3287266e-05",
         "-7.064067e-06",
         "-9.73845e-07",
         "-4.1953528e-05",
         "-9.051404e-06",
         "-3.0559586e-05",
         "-9.42669e-06",
         "7"
        ],
        [
         "19",
         "1.4402104e-06",
         "9.14444e-06",
         "4.4197654e-06",
         "2.7243425e-06",
         "-4.464669e-05",
         "1.5024201e-05",
         "-1.374796e-05",
         "1.4269367e-05",
         "-1.7127786e-05",
         "-4.124263e-05",
         "-1.0081397e-05",
         "-2.6011e-07",
         "-5.110919e-05",
         "-1.1379341e-05",
         "-3.406661e-05",
         "-1.0264083e-05",
         "7"
        ],
        [
         "20",
         "5.6295694e-06",
         "9.726861e-06",
         "4.754547e-06",
         "6.733321e-06",
         "-2.5778152e-05",
         "2.0685788e-05",
         "-3.9722713e-06",
         "1.9874351e-05",
         "-1.6667767e-05",
         "-3.3017757e-05",
         "-1.0060697e-05",
         "-1.13354716e-07",
         "-6.171663e-05",
         "-1.1076429e-05",
         "-3.5900382e-05",
         "-1.2851279e-05",
         "7"
        ],
        [
         "21",
         "7.715219e-06",
         "9.966491e-06",
         "4.8312695e-06",
         "1.2304053e-05",
         "-1.8266475e-05",
         "2.4728837e-05",
         "1.0051798e-06",
         "2.5830712e-05",
         "-1.5340926e-05",
         "-2.0744448e-05",
         "-9.040911e-06",
         "-5.051147e-06",
         "-6.9472306e-05",
         "-1.11910695e-05",
         "-3.7239064e-05",
         "-1.6191487e-05",
         "7"
        ],
        [
         "22",
         "8.6184e-06",
         "1.0843185e-05",
         "4.940762e-06",
         "1.892599e-05",
         "-2.2521983e-05",
         "2.6513799e-05",
         "-1.962752e-06",
         "2.7872778e-05",
         "-1.4576682e-05",
         "-5.2053724e-06",
         "-1.0646876e-05",
         "-1.3489409e-05",
         "-7.411307e-05",
         "-1.2451871e-05",
         "-3.5577083e-05",
         "-1.8710914e-05",
         "7"
        ],
        [
         "23",
         "1.2143116e-05",
         "1.2351145e-05",
         "7.952666e-06",
         "2.6214218e-05",
         "-3.561204e-05",
         "2.5783589e-05",
         "-9.420388e-06",
         "2.673874e-05",
         "-1.0319804e-05",
         "1.0437693e-05",
         "-1.3400135e-05",
         "-2.361975e-05",
         "-6.854437e-05",
         "-1.5250382e-05",
         "-2.8087165e-05",
         "-2.0335248e-05",
         "7"
        ],
        [
         "24",
         "2.1240168e-05",
         "1.6204662e-05",
         "1.3063392e-05",
         "3.232143e-05",
         "-4.083124e-05",
         "2.1604352e-05",
         "-1.4430955e-05",
         "2.3851784e-05",
         "-4.9206747e-06",
         "1.9142744e-05",
         "-1.7913262e-05",
         "-2.895106e-05",
         "-5.1184834e-05",
         "-1.64496e-05",
         "-1.8725272e-05",
         "-1.8835848e-05",
         "7"
        ],
        [
         "25",
         "3.6549005e-05",
         "2.3266888e-05",
         "1.6092727e-05",
         "3.5216726e-05",
         "-1.983006e-05",
         "1.5385322e-05",
         "-1.050152e-05",
         "1.9954121e-05",
         "-1.5460452e-06",
         "1.7863918e-05",
         "-2.1275006e-05",
         "-3.0424326e-05",
         "-3.248079e-05",
         "-1.5408697e-05",
         "-1.0551315e-05",
         "-1.4639229e-05",
         "7"
        ],
        [
         "26",
         "4.7702895e-05",
         "2.8706741e-05",
         "1.5242567e-05",
         "3.5279674e-05",
         "2.5834359e-05",
         "1.0817878e-05",
         "4.620638e-06",
         "1.7356459e-05",
         "7.90464e-07",
         "5.239312e-06",
         "-2.0652647e-05",
         "-2.7551341e-05",
         "-1.3104614e-05",
         "-1.1537724e-05",
         "-4.913965e-06",
         "-1.2003752e-05",
         "7"
        ],
        [
         "27",
         "4.3661046e-05",
         "2.9217845e-05",
         "1.2445458e-05",
         "3.3917142e-05",
         "6.672526e-05",
         "9.070111e-06",
         "2.0454487e-05",
         "1.4100585e-05",
         "3.6736703e-06",
         "-1.37404295e-05",
         "-1.777791e-05",
         "-2.5200332e-05",
         "1.4371933e-05",
         "-1.0399173e-05",
         "-2.3327614e-06",
         "-1.3725942e-05",
         "7"
        ],
        [
         "28",
         "1.9735076e-05",
         "2.85251e-05",
         "1.1801985e-05",
         "3.318821e-05",
         "6.814536e-05",
         "9.4662555e-06",
         "2.3843873e-05",
         "1.1312121e-05",
         "9.80369e-06",
         "-2.0770398e-05",
         "-1.6951677e-05",
         "-2.5377429e-05",
         "4.4958415e-05",
         "-1.2420078e-05",
         "-5.8383364e-07",
         "-1.5658512e-05",
         "7"
        ],
        [
         "29",
         "-1.35558785e-05",
         "2.9286535e-05",
         "1.258895e-05",
         "3.298257e-05",
         "3.932186e-05",
         "6.2873755e-06",
         "1.2384052e-05",
         "6.16527e-06",
         "9.221686e-06",
         "-7.854417e-06",
         "-1.8774006e-05",
         "-2.795083e-05",
         "6.677703e-05",
         "-1.1678629e-05",
         "9.5056487e-07",
         "-1.3964419e-05",
         "7"
        ],
        [
         "30",
         "-3.2097705e-05",
         "3.3211818e-05",
         "1.3962809e-05",
         "3.400369e-05",
         "9.588372e-06",
         "-4.4100793e-07",
         "-3.887511e-06",
         "-1.8799851e-06",
         "5.863094e-07",
         "1.1505012e-05",
         "-2.2724545e-05",
         "-3.0747564e-05",
         "8.08724e-05",
         "-7.62209e-06",
         "4.777849e-06",
         "-1.2450165e-05",
         "7"
        ],
        [
         "31",
         "-2.60404e-05",
         "3.7119673e-05",
         "1.6686541e-05",
         "3.4996967e-05",
         "-6.0182565e-06",
         "-9.1465745e-06",
         "-1.4940866e-05",
         "-8.982501e-06",
         "-1.4325978e-05",
         "1.09518505e-05",
         "-2.7312932e-05",
         "-3.183716e-05",
         "9.5644406e-05",
         "-3.9558477e-06",
         "9.600135e-06",
         "-1.23916625e-05",
         "7"
        ],
        [
         "32",
         "-9.9825265e-06",
         "3.7849964e-05",
         "1.8516923e-05",
         "3.182006e-05",
         "-1.4164747e-05",
         "-1.570555e-05",
         "-1.9431169e-05",
         "-1.2710638e-05",
         "-2.8510669e-05",
         "-1.881169e-05",
         "-2.9597317e-05",
         "-3.253939e-05",
         "9.941828e-05",
         "-1.9086742e-06",
         "1.06865045e-05",
         "-1.22641495e-05",
         "7"
        ],
        [
         "33",
         "4.9974474e-06",
         "3.4153945e-05",
         "1.5810134e-05",
         "2.4086881e-05",
         "-2.6738882e-05",
         "-1.8226923e-05",
         "-2.3595721e-05",
         "-1.4213751e-05",
         "-3.9702045e-05",
         "-6.447791e-05",
         "-2.9188835e-05",
         "-3.191736e-05",
         "7.695311e-05",
         "-5.586049e-07",
         "7.305939e-06",
         "-1.0495918e-05",
         "7"
        ],
        [
         "34",
         "1.9040623e-05",
         "2.8644241e-05",
         "1.1213727e-05",
         "1.5931966e-05",
         "-5.096898e-05",
         "-1.7955077e-05",
         "-3.0906613e-05",
         "-1.6251763e-05",
         "-4.628443e-05",
         "-0.00010674135",
         "-2.8108207e-05",
         "-3.153115e-05",
         "3.7644106e-05",
         "1.8251829e-07",
         "1.0004813e-06",
         "-6.1205756e-06",
         "7"
        ],
        [
         "35",
         "3.6093086e-05",
         "2.2481874e-05",
         "8.640415e-06",
         "1.0870111e-05",
         "-8.354973e-05",
         "-1.807601e-05",
         "-3.7920094e-05",
         "-2.0062702e-05",
         "-4.971122e-05",
         "-0.00013714941",
         "-2.843691e-05",
         "-3.1877225e-05",
         "5.3830904e-06",
         "9.3344056e-07",
         "-3.8897833e-06",
         "-2.027477e-06",
         "7"
        ],
        [
         "36",
         "5.6030283e-05",
         "2.1127094e-05",
         "8.369334e-06",
         "8.7210765e-06",
         "-0.000104356055",
         "-1.9144878e-05",
         "-4.329687e-05",
         "-2.5160985e-05",
         "-5.002731e-05",
         "-0.00013466484",
         "-2.7219525e-05",
         "-2.9862204e-05",
         "-8.385284e-06",
         "3.3716617e-07",
         "-7.063367e-06",
         "-3.6662095e-07",
         "7"
        ],
        [
         "37",
         "7.3774885e-05",
         "2.3771108e-05",
         "1.0421427e-05",
         "8.178007e-06",
         "-9.947045e-05",
         "-1.9570562e-05",
         "-4.2310337e-05",
         "-2.801695e-05",
         "-5.134812e-05",
         "-8.2856866e-05",
         "-2.5083524e-05",
         "-2.5434405e-05",
         "-1.31543975e-05",
         "-3.6033136e-06",
         "-8.44767e-06",
         "-1.2336001e-06",
         "7"
        ],
        [
         "38",
         "8.9608e-05",
         "2.2560225e-05",
         "1.0094774e-05",
         "5.930537e-06",
         "-7.3780815e-05",
         "-2.0485735e-05",
         "-3.894249e-05",
         "-2.9641831e-05",
         "-5.0484072e-05",
         "-2.688499e-05",
         "-2.4081837e-05",
         "-2.1653412e-05",
         "-2.1945969e-05",
         "-8.982003e-06",
         "-9.675023e-06",
         "-3.902918e-06",
         "7"
        ],
        [
         "39",
         "0.000101690544",
         "1.9600775e-05",
         "8.190023e-06",
         "4.1477488e-06",
         "-3.8375983e-05",
         "-2.0246638e-05",
         "-3.526201e-05",
         "-2.9887793e-05",
         "-4.4765806e-05",
         "-7.84459e-06",
         "-2.1471911e-05",
         "-2.1391726e-05",
         "-3.7223388e-05",
         "-1.1188126e-05",
         "-1.2841049e-05",
         "-5.4528887e-06",
         "7"
        ],
        [
         "40",
         "0.00010902343",
         "1.9266956e-05",
         "5.769989e-06",
         "3.6870824e-06",
         "-7.480307e-06",
         "-1.9518002e-05",
         "-3.1074247e-05",
         "-2.4814528e-05",
         "-3.4129804e-05",
         "-1.3467742e-05",
         "-1.845137e-05",
         "-2.239409e-05",
         "-5.3943426e-05",
         "-1.0820331e-05",
         "-1.646178e-05",
         "-4.1758226e-06",
         "7"
        ],
        [
         "41",
         "0.000104388004",
         "2.561599e-05",
         "5.0499607e-06",
         "4.4411995e-06",
         "1.6705926e-05",
         "-1.7268847e-05",
         "-2.8095528e-05",
         "-2.070817e-05",
         "-2.123867e-05",
         "-1.7066157e-05",
         "-1.6357893e-05",
         "-2.3554607e-05",
         "-6.7003595e-05",
         "-9.884873e-06",
         "-1.903707e-05",
         "-2.247556e-06",
         "7"
        ],
        [
         "42",
         "7.997347e-05",
         "3.454924e-05",
         "5.9125928e-06",
         "5.0305257e-06",
         "4.026618e-05",
         "-1.4670493e-05",
         "-2.4511932e-05",
         "-1.9803083e-05",
         "-1.11046475e-05",
         "-9.745156e-06",
         "-1.4459628e-05",
         "-2.4260813e-05",
         "-7.2401104e-05",
         "-1.1518544e-05",
         "-2.1163438e-05",
         "-1.26277e-06",
         "7"
        ],
        [
         "43",
         "4.0554914e-05",
         "4.143958e-05",
         "8.474668e-06",
         "6.0805232e-06",
         "5.5643173e-05",
         "-1.5910227e-05",
         "-1.7442138e-05",
         "-1.8249204e-05",
         "-6.816757e-06",
         "5.3191593e-06",
         "-1.1661677e-05",
         "-2.1926053e-05",
         "-6.608181e-05",
         "-1.3984392e-05",
         "-2.1803331e-05",
         "-2.5364657e-06",
         "7"
        ],
        [
         "44",
         "-1.5111629e-05",
         "4.144065e-05",
         "1.1134084e-05",
         "9.348167e-06",
         "5.5139528e-05",
         "-1.7652515e-05",
         "-4.4688218e-06",
         "-1.540684e-05",
         "-1.0846867e-05",
         "2.808267e-05",
         "-9.310537e-06",
         "-1.6960681e-05",
         "-4.8055153e-05",
         "-1.2653211e-05",
         "-2.0054285e-05",
         "-5.4339107e-06",
         "7"
        ],
        [
         "45",
         "-7.5428645e-05",
         "3.72791e-05",
         "1.0428188e-05",
         "1.275667e-05",
         "4.196867e-05",
         "-1.5107172e-05",
         "9.038561e-06",
         "-1.3099769e-05",
         "-1.6433618e-05",
         "5.6991415e-05",
         "-6.701742e-06",
         "-1.0444224e-05",
         "-2.4552148e-05",
         "-5.7267243e-06",
         "-1.6774098e-05",
         "-6.348991e-06",
         "7"
        ],
        [
         "46",
         "-0.00011345095",
         "3.4274275e-05",
         "9.122217e-06",
         "1.2347801e-05",
         "1.5507225e-05",
         "-1.0127984e-05",
         "1.3695292e-05",
         "-8.552749e-06",
         "-1.334446e-05",
         "7.649935e-05",
         "-4.6830437e-06",
         "-7.1746067e-06",
         "-1.4660357e-06",
         "3.2281491e-06",
         "-1.17807995e-05",
         "-9.241087e-08",
         "7"
        ],
        [
         "47",
         "-0.00010880077",
         "3.1831085e-05",
         "9.748975e-06",
         "8.184223e-06",
         "-3.3434004e-05",
         "-7.8597905e-06",
         "3.875986e-06",
         "-4.2216175e-06",
         "-1.6978178e-06",
         "8.007067e-05",
         "-4.344838e-06",
         "-9.00607e-06",
         "1.9656309e-05",
         "1.0839984e-05",
         "-5.6261656e-06",
         "4.772383e-06",
         "7"
        ],
        [
         "48",
         "-6.5121225e-05",
         "3.1208143e-05",
         "9.721605e-06",
         "5.590024e-06",
         "-9.9306715e-05",
         "-8.846511e-06",
         "-1.5731419e-05",
         "-4.3567047e-06",
         "9.484824e-06",
         "6.9545e-05",
         "-4.8289917e-06",
         "-1.1498534e-05",
         "3.1656324e-05",
         "1.19828355e-05",
         "-2.1464798e-06",
         "9.87239e-07",
         "7"
        ],
        [
         "49",
         "-1.49807875e-05",
         "2.9671543e-05",
         "1.0788957e-05",
         "7.754431e-06",
         "-0.00014274039",
         "-9.725171e-06",
         "-3.3803222e-05",
         "-6.7488913e-06",
         "1.1915434e-05",
         "4.9820774e-05",
         "-6.2803338e-06",
         "-1.3632867e-05",
         "3.2570308e-05",
         "9.586321e-06",
         "5.6874524e-07",
         "-7.888443e-06",
         "7"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 47973920
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>Restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47973915</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47973916</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47973917</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47973918</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47973919</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47973920 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5  \\\n",
       "0         0.000038  0.000025  0.000008  0.000008 -0.000016 -0.000002   \n",
       "1         0.000020  0.000026  0.000010  0.000008 -0.000017 -0.000002   \n",
       "2         0.000009  0.000026  0.000011  0.000008 -0.000024 -0.000004   \n",
       "3         0.000012  0.000023  0.000009  0.000007 -0.000041 -0.000009   \n",
       "4         0.000021  0.000020  0.000006  0.000005 -0.000044 -0.000015   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "47973915  0.000030  0.000042  0.000010  0.000012 -0.000030 -0.000011   \n",
       "47973916  0.000030  0.000060  0.000011  0.000013 -0.000030 -0.000009   \n",
       "47973917  0.000024  0.000074  0.000012  0.000014 -0.000029 -0.000006   \n",
       "47973918  0.000015  0.000077  0.000013  0.000016 -0.000027 -0.000005   \n",
       "47973919  0.000002  0.000076  0.000014  0.000018 -0.000026 -0.000006   \n",
       "\n",
       "                 6         7         8         9        10        11  \\\n",
       "0        -0.000005 -0.000010  0.000017  0.000061 -0.000008 -0.000008   \n",
       "1        -0.000008 -0.000007  0.000014  0.000043 -0.000011 -0.000009   \n",
       "2        -0.000013 -0.000005  0.000014  0.000025 -0.000015 -0.000011   \n",
       "3        -0.000016 -0.000006  0.000012  0.000010 -0.000017 -0.000012   \n",
       "4        -0.000018 -0.000008  0.000007  0.000003 -0.000016 -0.000011   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "47973915 -0.000027 -0.000002 -0.000092 -0.000030 -0.000013 -0.000016   \n",
       "47973916 -0.000026 -0.000013 -0.000086 -0.000012 -0.000010 -0.000015   \n",
       "47973917 -0.000025 -0.000014 -0.000072  0.000002 -0.000010 -0.000016   \n",
       "47973918 -0.000021 -0.000014 -0.000051  0.000002 -0.000012 -0.000017   \n",
       "47973919 -0.000016 -0.000017 -0.000028 -0.000007 -0.000014 -0.000018   \n",
       "\n",
       "                12        13        14        15  Restimulus  \n",
       "0        -0.000022 -0.000008 -0.000016 -0.000013           7  \n",
       "1        -0.000022 -0.000012 -0.000016 -0.000018           7  \n",
       "2        -0.000018 -0.000013 -0.000013 -0.000016           7  \n",
       "3        -0.000014 -0.000013 -0.000008 -0.000013           7  \n",
       "4        -0.000012 -0.000014 -0.000006 -0.000012           7  \n",
       "...            ...       ...       ...       ...         ...  \n",
       "47973915 -0.000010 -0.000008 -0.000013 -0.000011          18  \n",
       "47973916 -0.000009 -0.000008 -0.000014 -0.000011          18  \n",
       "47973917 -0.000011 -0.000008 -0.000014 -0.000013          18  \n",
       "47973918 -0.000013 -0.000006 -0.000013 -0.000014          18  \n",
       "47973919 -0.000014 -0.000006 -0.000012 -0.000015          18  \n",
       "\n",
       "[47973920 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nature df csv불러오는 코드\n",
    "nature_df = pd.read_csv('nature_df.csv')\n",
    "nature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d04ecbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 처리 시작: 47973920 rows\n",
      "Sampling Rate 변환: 2000Hz -> 1000Hz (Downsampling)\n",
      "총 815개의 동작 세그먼트가 발견되었습니다. 변환 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Segments: 100%|██████████| 815/815 [00:52<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩(Padding) 및 최종 배열 생성 중...\n",
      "----------------------------------------\n",
      "처리가 완료되었습니다.\n",
      "입력 데이터 Shape (X): (783, 50040, 16)\n",
      "라벨 데이터 Shape (y): (783,)\n",
      "메모리 사용량(예상): 2.34 GB\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#down sampling code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm  # 진행 상황 표시용 (설치 필요: pip install tqdm)\n",
    "\n",
    "def process_large_emg_data(df):\n",
    "    \"\"\"\n",
    "    4800만 행 규모의 2000Hz EMG 데이터를 처리하여 1D CNN 모델 입력용 Numpy 배열로 변환\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): 2000Hz Raw 데이터 (Rows x 17 cols)\n",
    "                           (1~16 col: EMG 센서, 17 col: Restimulus 클래스)\n",
    "    \n",
    "    Returns:\n",
    "        X_padded (np.array): (Batch_Size, Max_Time_Steps, 16)\n",
    "        y_labels (np.array): (Batch_Size,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 1. 설정 및 준비\n",
    "    # ---------------------------------------------------------\n",
    "    ORIGINAL_FS = 2000  # 원본 주파수\n",
    "    TARGET_FS = 1000    # 목표 주파수\n",
    "    RATIO = TARGET_FS / ORIGINAL_FS  # 0.5 (절반으로 축소)\n",
    "\n",
    "    feature_cols = df.columns[:-1]  # 앞의 16개 컬럼 (EMG)\n",
    "    label_col = df.columns[-1]      # 마지막 컬럼 (Restimulus)\n",
    "    \n",
    "    print(f\"데이터 처리 시작: {len(df)} rows\")\n",
    "    print(f\"Sampling Rate 변환: {ORIGINAL_FS}Hz -> {TARGET_FS}Hz (Downsampling)\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. 세그먼트 분할 (Segmentation)\n",
    "    # Restimulus 값이 바뀌는 지점을 기준으로 그룹 ID 생성\n",
    "    # ---------------------------------------------------------\n",
    "    # 대용량 데이터이므로 메모리 효율을 위해 필요한 컬럼만 사용하여 연산\n",
    "    df['segment_id'] = (df[label_col] != df[label_col].shift()).cumsum()\n",
    "    \n",
    "    processed_segments = []\n",
    "    labels = []\n",
    "    \n",
    "    # 그룹핑 (메모리 절약을 위해 groupby 객체를 바로 순회)\n",
    "    grouped = df.groupby('segment_id')\n",
    "    \n",
    "    print(f\"총 {len(grouped)}개의 동작 세그먼트가 발견되었습니다. 변환 중...\")\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 3. 반복 처리 (Downsampling -> Normalization)\n",
    "    # ---------------------------------------------------------\n",
    "    for _, group in tqdm(grouped, desc=\"Processing Segments\"):\n",
    "        # 현재 클래스 라벨\n",
    "        current_label = group[label_col].iloc[0]\n",
    "        \n",
    "        # (옵션) 0번(휴식) 클래스를 제외하려면 아래 주석 해제\n",
    "        if current_label == 0: continue\n",
    "\n",
    "        # 센서 데이터 추출 (Numpy 변환)\n",
    "        raw_signals = group[feature_cols].to_numpy() # .values 보다 to_numpy() 권장\n",
    "        \n",
    "        # 데이터 길이가 너무 짧으면(예: 노이즈) 스킵하는 로직 추가 가능\n",
    "        if len(raw_signals) < 2:\n",
    "            continue\n",
    "\n",
    "        # [Downsampling] 2000Hz -> 1000Hz\n",
    "        # 목표 샘플 수 계산\n",
    "        new_num_samples = int(len(raw_signals) * RATIO)\n",
    "        \n",
    "        if new_num_samples > 0:\n",
    "            # Fourier method 리샘플링 (데이터가 많으므로 signal.decimate(x, 2)도 고려 가능)\n",
    "            # 여기서는 길이를 정확히 제어하기 위해 resample 사용\n",
    "            resampled_signals = signal.resample(raw_signals, new_num_samples)\n",
    "            \n",
    "            # [Z-score Normalization]\n",
    "            # 각 세그먼트별로 독립적으로 정규화\n",
    "            scaler = StandardScaler()\n",
    "            normalized_signals = scaler.fit_transform(resampled_signals)\n",
    "            \n",
    "            # 리스트에 저장 (float32로 변환하여 메모리 절약 권장)\n",
    "            processed_segments.append(normalized_signals.astype(np.float32))\n",
    "            labels.append(current_label)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4. 패딩 (Padding) 및 최종 변환\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"패딩(Padding) 및 최종 배열 생성 중...\")\n",
    "    \n",
    "    # 가장 긴 시퀀스 길이 찾기\n",
    "    max_len = max(len(seg) for seg in processed_segments)\n",
    "    num_samples = len(processed_segments)\n",
    "    num_channels = len(feature_cols)\n",
    "    \n",
    "    # 결과 배열 생성 (메모리 효율을 위해 float32 사용)\n",
    "    # Shape: (Batch_Size, Max_Time_Steps, Channels)\n",
    "    X_final = np.zeros((num_samples, max_len, num_channels), dtype=np.float32)\n",
    "    y_final = np.array(labels, dtype=np.int32)\n",
    "    \n",
    "    # 패딩 적용 (Post-padding: 뒤쪽을 0으로 채움)\n",
    "    for i, seg in enumerate(processed_segments):\n",
    "        length = len(seg)\n",
    "        X_final[i, :length, :] = seg\n",
    "        \n",
    "    print(\"-\" * 40)\n",
    "    print(\"처리가 완료되었습니다.\")\n",
    "    print(f\"입력 데이터 Shape (X): {X_final.shape}\")\n",
    "    print(f\"라벨 데이터 Shape (y): {y_final.shape}\")\n",
    "    print(f\"메모리 사용량(예상): {X_final.nbytes / 1024**3:.2f} GB\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    return X_final, y_final\n",
    "\n",
    "# 3. 함수 실행\n",
    "X_down, y_down = process_large_emg_data(nature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86cf83d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 3. 데이터 병합 (Merging) ===\n",
      "병합 시작...\n",
      "데이터셋 1 Shape: (1020, 7245, 16)\n",
      "데이터셋 2 Shape: (783, 50040, 16)\n",
      "통합 후 목표 Shape: (1803, 50040, 16)\n",
      "병합 완료.\n",
      "----------------------------------------\n",
      "최종 모델 입력 데이터 Shape (X): (1803, 50040, 16)\n",
      "최종 모델 라벨 데이터 Shape (y): (1803,)\n",
      "데이터 타입: float32\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#combin data code\n",
    "import numpy as np\n",
    "import gc  # 가비지 컬렉션(메모리 관리용)\n",
    "\n",
    "def merge_datasets(X1, y1, X2, y2):\n",
    "    \"\"\"\n",
    "    서로 다른 길이를 가진 두 개의 3차원 Numpy 배열을 병합합니다.\n",
    "    가장 긴 시퀀스 길이를 기준으로 Zero-padding을 수행합니다.\n",
    "    \"\"\"\n",
    "    print(f\"병합 시작...\")\n",
    "    print(f\"데이터셋 1 Shape: {X1.shape}\")\n",
    "    print(f\"데이터셋 2 Shape: {X2.shape}\")\n",
    "\n",
    "    # 1. 통합 차원 계산\n",
    "    # 샘플 수 합계\n",
    "    total_samples = X1.shape[0] + X2.shape[0]\n",
    "    # 두 데이터 중 더 긴 시퀀스 길이 선택 (여기서는 125080 예상)\n",
    "    max_seq_len = max(X1.shape[1], X2.shape[1])\n",
    "    num_channels = X1.shape[2] # 16\n",
    "\n",
    "    print(f\"통합 후 목표 Shape: ({total_samples}, {max_seq_len}, {num_channels})\")\n",
    "    \n",
    "    # 2. 메모리 할당 (Float32로 메모리 절약)\n",
    "    # 한 번에 큰 메모리를 할당하고 데이터를 밀어넣는 방식이 가장 효율적입니다.\n",
    "    X_final = np.zeros((total_samples, max_seq_len, num_channels), dtype=np.float32)\n",
    "    y_final = np.zeros((total_samples,), dtype=y1.dtype) # 라벨용\n",
    "\n",
    "    # 3. 데이터 채워넣기 (Padding 자동 적용)\n",
    "    # X1 (업샘플링 데이터) 넣기\n",
    "    # X1의 길이만큼만 앞부분에 채워지고, 나머지는 0으로 남음 (Post-padding 효과)\n",
    "    len1 = X1.shape[1]\n",
    "    X_final[:X1.shape[0], :len1, :] = X1\n",
    "    y_final[:y1.shape[0]] = y1\n",
    "\n",
    "    # X2 (다운샘플링 데이터) 넣기\n",
    "    # X1이 끝난 지점부터 시작\n",
    "    len2 = X2.shape[1]\n",
    "    X_final[X1.shape[0]:, :len2, :] = X2\n",
    "    y_final[y1.shape[0]:] = y2\n",
    "\n",
    "    print(\"병합 완료.\")\n",
    "    return X_final, y_final\n",
    "\n",
    "# ========================================================\n",
    "# [실행 코드] 변수명 분리 및 병합\n",
    "# ========================================================\n",
    "\n",
    "print(\"\\n=== 3. 데이터 병합 (Merging) ===\")\n",
    "# 병합 함수 실행\n",
    "X_combined, y_combined = merge_datasets(X_up, y_up, X_down, y_down)\n",
    "\n",
    "# 메모리 확보를 위해 이전 변수 삭제 (선택사항)\n",
    "del X_up, y_up, X_down, y_down\n",
    "gc.collect()\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"최종 모델 입력 데이터 Shape (X): {X_combined.shape}\")\n",
    "print(f\"최종 모델 라벨 데이터 Shape (y): {y_combined.shape}\")\n",
    "print(f\"데이터 타입: {X_combined.dtype}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 이 X_combined, y_combined를 1D CNN Encoder Attention 모델에 넣으시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e407eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 저장을 시작합니다. 대상 폴더: ./processed_data\n",
      "1. X_combined.npy 저장 중... (시간이 소요될 수 있습니다)\n",
      "2. y_combined.npy 저장 중...\n",
      "일반 저장 완료.\n",
      "3. 압축 저장 시작 (권장): ./processed_data\\emg_data_compressed.npz ...\n",
      "모든 저장이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 저장할 폴더 생성 (현재 경로에 data 폴더 생성)\n",
    "save_dir = './processed_data'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "print(f\"데이터 저장을 시작합니다. 대상 폴더: {save_dir}\")\n",
    "\n",
    "# ========================================================\n",
    "# Method 1: 일반 .npy 파일로 저장 (속도 빠름, 용량 큼)\n",
    "# ========================================================\n",
    "# X_combined.npy와 y_combined.npy로 각각 저장됩니다.\n",
    "# 예상 용량: 약 23GB\n",
    "\n",
    "print(\"1. X_combined.npy 저장 중... (시간이 소요될 수 있습니다)\")\n",
    "np.save(os.path.join(save_dir, 'X_combined.npy'), X_combined)\n",
    "\n",
    "print(\"2. y_combined.npy 저장 중...\")\n",
    "np.save(os.path.join(save_dir, 'y_combined.npy'), y_combined)\n",
    "\n",
    "print(\"일반 저장 완료.\")\n",
    "\n",
    "# ========================================================\n",
    "# Method 2: 압축된 .npz 파일로 저장 (권장)\n",
    "# ========================================================\n",
    "# 패딩으로 채워진 0이 많으므로 용량이 1/10 이하로 줄어들 가능성이 큽니다.\n",
    "# 나중에 로드할 때는 np.load()['X'] 형태로 불러옵니다.\n",
    "\n",
    "save_path_compressed = os.path.join(save_dir, 'emg_data_compressed.npz')\n",
    "print(f\"3. 압축 저장 시작 (권장): {save_path_compressed} ...\")\n",
    "\n",
    "np.savez_compressed(save_path_compressed, X=X_combined, y=y_combined)\n",
    "\n",
    "print(\"모든 저장이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113ea7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 데이터 로딩 중...\n",
      "🔄 원본 데이터 형태: (1803, 50040, 16)\n",
      "✅ 데이터 형태 유지됨: (Time, Channels)\n",
      "📌 최종 설정 - Window Size(Time): 50040, Channels: 16\n",
      "WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Channel_Temporal_Attention_EMG\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Channel_Temporal_Attention_EMG\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50040</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50040</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50040</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50040</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │                   │            │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50040</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,200</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25020</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25020</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25020</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12510</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12510</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12510</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12510</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12510</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ softmax[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,235</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50040\u001b[0m, \u001b[38;5;34m16\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50040\u001b[0m, \u001b[38;5;34m32\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50040\u001b[0m, \u001b[38;5;34m32\u001b[0m) │        \u001b[38;5;34m128\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m264\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m288\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50040\u001b[0m, \u001b[38;5;34m32\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │                   │            │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50040\u001b[0m, \u001b[38;5;34m32\u001b[0m) │      \u001b[38;5;34m7,200\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25020\u001b[0m, \u001b[38;5;34m32\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25020\u001b[0m, \u001b[38;5;34m32\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25020\u001b[0m, \u001b[38;5;34m64\u001b[0m) │      \u001b[38;5;34m6,208\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12510\u001b[0m, \u001b[38;5;34m64\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12510\u001b[0m, \u001b[38;5;34m32\u001b[0m) │      \u001b[38;5;34m2,080\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12510\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │         \u001b[38;5;34m33\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12510\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12510\u001b[0m, \u001b[38;5;34m64\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ softmax[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │      \u001b[38;5;34m1,235\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,108</span> (86.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,108\u001b[0m (86.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,044</span> (86.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,044\u001b[0m (86.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 학습 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 10s/step - accuracy: 0.0725 - loss: 2.8934 - val_accuracy: 0.1191 - val_loss: 2.9300 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 10s/step - accuracy: 0.1158 - loss: 2.7538 - val_accuracy: 0.1219 - val_loss: 2.9259 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 10s/step - accuracy: 0.1111 - loss: 2.6714 - val_accuracy: 0.1247 - val_loss: 2.9045 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 9s/step - accuracy: 0.1006 - loss: 2.6504 - val_accuracy: 0.1247 - val_loss: 2.8886 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 10s/step - accuracy: 0.0936 - loss: 2.6351 - val_accuracy: 0.1247 - val_loss: 2.8274 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 9s/step - accuracy: 0.1064 - loss: 2.6199 - val_accuracy: 0.1247 - val_loss: 2.7707 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 10s/step - accuracy: 0.1053 - loss: 2.5921 - val_accuracy: 0.1302 - val_loss: 2.6697 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 10s/step - accuracy: 0.1240 - loss: 2.5686 - val_accuracy: 0.1773 - val_loss: 2.6142 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 10s/step - accuracy: 0.1053 - loss: 2.5674 - val_accuracy: 0.1524 - val_loss: 2.6022 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 10s/step - accuracy: 0.1415 - loss: 2.5534 - val_accuracy: 0.1884 - val_loss: 2.4753 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 10s/step - accuracy: 0.1029 - loss: 2.5509 - val_accuracy: 0.1911 - val_loss: 2.4135 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m 8/45\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:44\u001b[0m 9s/step - accuracy: 0.1257 - loss: 2.5266"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 182\u001b[0m\n\u001b[0;32m    174\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    175\u001b[0m         train_gen,\n\u001b[0;32m    176\u001b[0m         validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val),\n\u001b[0;32m    177\u001b[0m         epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m    178\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks\n\u001b[0;32m    179\u001b[0m     )\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 182\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 174\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    167\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    168\u001b[0m     EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m    169\u001b[0m     ModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_channel_attention_model.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m    170\u001b[0m     ReduceLROnPlateau(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    171\u001b[0m ]\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🚀 학습 시작...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 174\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(begin_step)\n\u001b[1;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import os, gc\n",
    "\n",
    "# ====================================================\n",
    "# 1. Balanced Data Generator (수정 없음)\n",
    "# ====================================================\n",
    "class BalancedDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x, y, batch_size=32):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.classes = np.unique(y)\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.class_indices = [np.where(y == c)[0] for c in self.classes]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        bx, by = [], []\n",
    "        samples_per_class = self.batch_size // self.num_classes\n",
    "\n",
    "        for i, c in enumerate(self.classes):\n",
    "            # 샘플이 부족할 경우 replace=True로 중복 허용\n",
    "            indices = np.random.choice(self.class_indices[i],\n",
    "                                       samples_per_class,\n",
    "                                       replace=True)\n",
    "            bx.append(self.x[indices])\n",
    "            by.append(self.y[indices])\n",
    "\n",
    "        bx = np.concatenate(bx)\n",
    "        by = np.concatenate(by)\n",
    "        p = np.random.permutation(len(bx))\n",
    "        return bx[p], by[p]\n",
    "\n",
    "# ====================================================\n",
    "# 2. Channel Attention (SE Block)\n",
    "# ====================================================\n",
    "def channel_attention(x, reduction=4): # reduction 비율 조정\n",
    "    # x shape: (Batch, Time, Channels)\n",
    "    channels = x.shape[-1] \n",
    "    \n",
    "    # GlobalAveragePooling1D는 Time 축을 평균냄 -> (Batch, Channels)\n",
    "    se = layers.GlobalAveragePooling1D()(x)\n",
    "    se = layers.Dense(max(1, channels // reduction), activation='relu')(se) # 최소 1 보장\n",
    "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
    "    se = layers.Reshape((1, channels))(se) # (Batch, 1, Channels)\n",
    "\n",
    "    # Broadcasting: (Batch, Time, Channels) * (Batch, 1, Channels)\n",
    "    return layers.Multiply()([x, se])\n",
    "\n",
    "# ====================================================\n",
    "# 3. Channel-wise CNN + Attention Model (구조 개선)\n",
    "# ====================================================\n",
    "def build_channel_temporal_attention_model(num_classes, channels, window_size, d_model=64):\n",
    "    # 입력: (Batch, Time, Channels) 형태로 받는 것이 Keras 표준에 더 적합합니다.\n",
    "    # 하지만 기존 데이터가 (Channels, Time)일 수 있으므로 입력 정의는 유연하게 합니다.\n",
    "    \n",
    "    # [수정] 입력 형태를 명확히 (Time, Channels)로 가정하고 설계\n",
    "    # TimeDistributed나 Conv1D는 기본적으로 (Batch, Time, Channels)를 입력으로 받습니다.\n",
    "    inputs = Input(shape=(window_size, channels)) \n",
    "\n",
    "    # ===== Channel-wise CNN =====\n",
    "    # groups=channels를 쓰면 각 채널별로 독립적인 Conv 연산을 수행합니다 (Depthwise Conv)\n",
    "    x = layers.Conv1D(\n",
    "        filters=channels * 2, # 채널 수의 2배로 확장\n",
    "        kernel_size=15,\n",
    "        padding=\"same\",\n",
    "        groups=channels,      # 🔥 각 채널 독립 연산\n",
    "        activation=\"relu\",\n",
    "        kernel_regularizer=regularizers.l2(0.01)\n",
    "    )(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # ===== Channel Attention =====\n",
    "    x = channel_attention(x)\n",
    "\n",
    "    # ===== Temporal Feature Extraction =====\n",
    "    x = layers.Conv1D(32, 7, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Conv1D(d_model, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "\n",
    "    # ===== Temporal Attention =====\n",
    "    attn = layers.Dense(d_model // 2, activation=\"tanh\")(x)\n",
    "    attn_score = layers.Dense(1)(attn)\n",
    "    attn_weight = layers.Softmax(axis=1)(attn_score)\n",
    "\n",
    "    x = layers.Multiply()([x, attn_weight])\n",
    "    \n",
    "    # 안전한 합산 (Lambda 대신 reduce_sum 직접 사용 가능하지만 Lambda도 무방)\n",
    "    x = layers.Lambda(lambda z: tf.reduce_sum(z, axis=1))(x)\n",
    "\n",
    "    # ===== Classifier =====\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    return models.Model(inputs, outputs, name=\"Channel_Temporal_Attention_EMG\")\n",
    "\n",
    "# ====================================================\n",
    "# 4. Training (차원 자동 감지 기능 추가)\n",
    "# ====================================================\n",
    "def train():\n",
    "    base_path = r'C:\\python_pj\\Project-Gesture-classification-technique-based-on-multiple-EMG-datasets\\processed_data'\n",
    "\n",
    "    print(\"📂 데이터 로딩 중...\")\n",
    "    X = np.load(os.path.join(base_path, 'X_combined.npy')).astype(np.float32)\n",
    "    y = np.load(os.path.join(base_path, 'y_combined.npy'))\n",
    "\n",
    "    # [핵심 수정] 차원 확인 및 자동 정렬\n",
    "    print(f\"🔄 원본 데이터 형태: {X.shape}\")\n",
    "    n, dim1, dim2 = X.shape\n",
    "    \n",
    "    # 보통 EMG 데이터에서 (16, 500) 또는 (500, 16) 중 작은 숫자가 채널입니다.\n",
    "    if dim1 < dim2:\n",
    "        channels, window_size = dim1, dim2\n",
    "        # 모델 학습을 위해 (Batch, Time, Channels) 형태인 (N, 500, 16)으로 변경 권장\n",
    "        # 현재 (N, 16, 500) -> (N, 500, 16)\n",
    "        X = np.transpose(X, (0, 2, 1))\n",
    "        print(f\"✅ 데이터 전치 수행됨: (Channels, Time) -> (Time, Channels)\")\n",
    "    else:\n",
    "        window_size, channels = dim1, dim2\n",
    "        print(f\"✅ 데이터 형태 유지됨: (Time, Channels)\")\n",
    "\n",
    "    print(f\"📌 최종 설정 - Window Size(Time): {window_size}, Channels: {channels}\")\n",
    "\n",
    "    # ===== Normalize =====\n",
    "    # (N, Time, Channels) 형태 기준 정규화\n",
    "    X = X.reshape(n, -1)\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X = X.reshape(n, window_size, channels) # 순서 주의\n",
    "\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    num_classes = len(np.unique(y))\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    train_gen = BalancedDataGenerator(X_train, y_train, batch_size=32)\n",
    "\n",
    "    # 모델 생성 시 올바른 파라미터 전달\n",
    "    model = build_channel_temporal_attention_model(\n",
    "        num_classes=num_classes,\n",
    "        channels=channels,       # 16이어야 함\n",
    "        window_size=window_size  # 50000 등 큰 숫자여야 함\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(1e-3),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        ModelCheckpoint(\"best_channel_attention_model.keras\", save_best_only=True),\n",
    "        ReduceLROnPlateau(patience=3, factor=0.5, verbose=1)\n",
    "    ]\n",
    "\n",
    "    print(\"🚀 학습 시작...\")\n",
    "    model.fit(\n",
    "        train_gen,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40d946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
