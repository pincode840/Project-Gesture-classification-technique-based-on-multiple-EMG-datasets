{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34fad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy import signal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ==========================================\n",
    "# 1. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (ì „ì²˜ë¦¬ ë° ë§ˆìŠ¤í‚¹ í†µí•©)\n",
    "# ==========================================\n",
    "class IntegratedEMGDataset(Dataset):\n",
    "    def __init__(self, file_paths, target_freq=1000, window_ms=500, target_channels=16):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_paths (list): .mat íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "            target_freq (int): í†µì¼í•  ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜ (Hz)\n",
    "            window_ms (int): ìœˆë„ìš° í¬ê¸° (ms)\n",
    "            target_channels (int): ìµœëŒ€ ì±„ë„ ìˆ˜ (ë³´í†µ 16)\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.masks = []\n",
    "        self.window_size = int(target_freq * (window_ms / 1000))\n",
    "        \n",
    "        for fp in file_paths:\n",
    "            self._load_and_process(fp, target_freq, target_channels)\n",
    "\n",
    "    def _load_and_process(self, file_path, target_freq, target_channels):\n",
    "        try:\n",
    "            mat = scipy.io.loadmat(file_path)\n",
    "        except:\n",
    "            print(f\"File load error: {file_path}\")\n",
    "            return\n",
    "\n",
    "        # 1-1. ë³€ìˆ˜ëª… ë§¤í•‘ (Ninapro, Kaggle ë“± ë°ì´í„°ì…‹ ëŒ€ì‘)\n",
    "        if 'emg' in mat: raw_emg = mat['emg']\n",
    "        elif 'data' in mat: raw_emg = mat['data'].T # (Ch, Time) -> (Time, Ch)\n",
    "        else: return\n",
    "\n",
    "        if 'stimulus' in mat: raw_label = mat['stimulus']\n",
    "        elif 'restimulus' in mat: raw_label = mat['restimulus']\n",
    "        else: raw_label = np.zeros((raw_emg.shape[0], 1))\n",
    "\n",
    "        # 1-2. ì›ë³¸ ì£¼íŒŒìˆ˜ ì¶”ì • ë° í•„í„°ë§\n",
    "        # íŒŒì¼ëª…ì´ë‚˜ ë°ì´í„° íŠ¹ì„±ì— ë”°ë¼ ë¶„ê¸° (DB5=200Hz, DB2=2000Hz ë“±)\n",
    "        if 'db5' in file_path.lower(): original_freq = 200\n",
    "        elif 'db1' in file_path.lower(): original_freq = 100\n",
    "        else: original_freq = 2000 # ê¸°ë³¸ê°’\n",
    "        \n",
    "        # í•„í„°ë§ (Nyquist ê³ ë ¤)\n",
    "        nyq = 0.5 * original_freq\n",
    "        if nyq > 450: # ê³ í•´ìƒë„ ë°ì´í„°\n",
    "            b, a = signal.butter(4, [20/nyq, 450/nyq], btype='band')\n",
    "            emg_filtered = signal.filtfilt(b, a, raw_emg, axis=0)\n",
    "        elif nyq > 20: # ì €í•´ìƒë„ ë°ì´í„° (High-pass only)\n",
    "            b, a = signal.butter(4, 20/nyq, btype='high')\n",
    "            emg_filtered = signal.filtfilt(b, a, raw_emg, axis=0)\n",
    "        else:\n",
    "            emg_filtered = raw_emg\n",
    "\n",
    "        # 1-3. Resampling\n",
    "        num_samples = int(len(emg_filtered) * target_freq / original_freq)\n",
    "        emg_resampled = signal.resample(emg_filtered, num_samples, axis=0)\n",
    "        label_resampled = signal.resample(raw_label, num_samples, axis=0).round().astype(int)\n",
    "\n",
    "        # ì •ê·œí™” (Standardization)\n",
    "        emg_resampled = (emg_resampled - np.mean(emg_resampled, axis=0)) / (np.std(emg_resampled, axis=0) + 1e-6)\n",
    "\n",
    "        # 1-4. Sliding Window & Zero-Padding\n",
    "        curr_channels = emg_resampled.shape[1]\n",
    "        step = int(self.window_size * 0.5) # 50% overlap\n",
    "\n",
    "        for i in range(0, len(emg_resampled) - self.window_size, step):\n",
    "            window_x = emg_resampled[i:i+self.window_size, :]\n",
    "            window_y = label_resampled[i:i+self.window_size]\n",
    "            \n",
    "            # ë¼ë²¨ ê²°ì • (ìµœë¹ˆê°’)\n",
    "            vals, counts = np.unique(window_y, return_counts=True)\n",
    "            label = vals[np.argmax(counts)]\n",
    "            if label == 0: continue # íœ´ì‹(Rest) ì œì™¸\n",
    "            \n",
    "            # Padding & Masking\n",
    "            # ì…ë ¥: (Time, Ch) -> ì „ì¹˜ -> (Ch, Time)\n",
    "            x_tensor = torch.FloatTensor(window_x.T) \n",
    "            \n",
    "            if curr_channels < target_channels:\n",
    "                pad_len = target_channels - curr_channels\n",
    "                padding = torch.zeros(pad_len, self.window_size)\n",
    "                x_padded = torch.cat([x_tensor, padding], dim=0)\n",
    "                mask = torch.cat([torch.ones(curr_channels), torch.zeros(pad_len)], dim=0)\n",
    "            else:\n",
    "                x_padded = x_tensor[:target_channels, :] # 16ì±„ë„ ì´ˆê³¼ëŠ” ìë¦„\n",
    "                mask = torch.ones(target_channels)\n",
    "\n",
    "            self.data.append(x_padded)\n",
    "            self.labels.append(label)\n",
    "            self.masks.append(mask)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Labelì„ 0ë¶€í„° ì‹œì‘í•˜ê²Œ ì¡°ì • (í•„ìš” ì‹œ)\n",
    "        return self.data[idx], torch.tensor(self.labels[idx], dtype=torch.long) - 1, self.masks[idx]\n",
    "\n",
    "# ==========================================\n",
    "# 2. ëª¨ë¸ ì•„í‚¤í…ì²˜ (CWE-AP Model)\n",
    "# ==========================================\n",
    "class ChannelAgnosticNetwork(nn.Module):\n",
    "    def __init__(self, num_classes=17, d_model=128, window_size=500):\n",
    "        super(ChannelAgnosticNetwork, self).__init__()\n",
    "        \n",
    "        # [Stage 1] Shared Encoder (1D-CNN)\n",
    "        # ëª¨ë“  ì±„ë„ì´ ì´ ë ˆì´ì–´ë¥¼ ê³µìœ í•¨\n",
    "        self.shared_encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=15, padding=7),\n",
    "            nn.BatchNorm1d(32), nn.ReLU(), nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Conv1d(64, d_model, kernel_size=3, padding=1),\n",
    "            nn.AdaptiveAvgPool1d(1), # ì‹œê°„ì¶•ì„ 1ê°œë¡œ ì••ì¶•\n",
    "            nn.Flatten()             # (B*C, d_model)\n",
    "        )\n",
    "        \n",
    "        # [Stage 2] Attention Mechanism\n",
    "        self.attn_fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        x: (Batch, 16, 500)\n",
    "        mask: (Batch, 16) - ì‹¤ì œ ë°ì´í„°=1, íŒ¨ë”©=0\n",
    "        \"\"\"\n",
    "        B, C, T = x.shape\n",
    "        \n",
    "        # 1. Reshape for Shared Encoder\n",
    "        # (Batch * Channel, 1, Time)\n",
    "        x_reshaped = x.view(B * C, 1, T)\n",
    "        \n",
    "        # 2. Local Feature Extraction\n",
    "        features = self.shared_encoder(x_reshaped) # (B*C, d_model)\n",
    "        features = features.view(B, C, -1)         # (B, C, d_model)\n",
    "        \n",
    "        # 3. Masked Attention Pooling\n",
    "        # Attention Score ê³„ì‚°\n",
    "        attn_scores = self.attn_fc(features).squeeze(-1) # (B, C)\n",
    "        \n",
    "        # Masking: íŒ¨ë”©ëœ ì±„ë„ì˜ ì ìˆ˜ë¥¼ ë§¤ìš° ë‚®ê²Œ ì„¤ì •í•˜ì—¬ Softmaxì—ì„œ 0ì´ ë˜ê²Œ í•¨\n",
    "        if mask is not None:\n",
    "            mask_bool = (mask == 0) # True where padding exists\n",
    "            attn_scores = attn_scores.masked_fill(mask_bool, -1e9)\n",
    "            \n",
    "        attn_weights = torch.softmax(attn_scores, dim=1).unsqueeze(-1) # (B, C, 1)\n",
    "        \n",
    "        # Weighted Sum (Channel Dimension í†µí•©)\n",
    "        # (B, C, d) * (B, C, 1) -> sum(dim=1) -> (B, d)\n",
    "        global_feature = torch.sum(features * attn_weights, dim=1)\n",
    "        \n",
    "        # 4. Classification\n",
    "        out = self.classifier(global_feature)\n",
    "        return out\n",
    "\n",
    "# ==========================================\n",
    "# 3. ì‹¤í–‰ ë° í•™ìŠµ ë£¨í”„ ì˜ˆì‹œ\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. ë°ì´í„° ì¤€ë¹„ (ê²½ë¡œ ë¦¬ìŠ¤íŠ¸)\n",
    "    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” .mat íŒŒì¼ ê²½ë¡œë“¤ì„ ë¦¬ìŠ¤íŠ¸ì— ë„£ìœ¼ì„¸ìš”.\n",
    "    file_list = [\n",
    "        \"S1_E2_A1.mat\", \n",
    "        # \"Subject2_session1.mat\", \n",
    "        # \"Kaggle_User1.mat\" \n",
    "    ]\n",
    "    \n",
    "    # íŒŒì¼ì´ ì‹¤ì œë¡œ ìˆì„ ë•Œë§Œ ì‹¤í–‰\n",
    "    if os.path.exists(file_list[0]):\n",
    "        dataset = IntegratedEMGDataset(file_list, target_channels=16)\n",
    "        \n",
    "        # Train/Test Split\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        test_size = len(dataset) - train_size\n",
    "        train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        # 2. ëª¨ë¸ ì´ˆê¸°í™”\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = ChannelAgnosticNetwork(num_classes=17).to(device) # í´ë˜ìŠ¤ ìˆ˜ëŠ” ë°ì´í„°ì…‹ì— ë§ê²Œ ì¡°ì •\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # 3. í•™ìŠµ ë£¨í”„\n",
    "        print(\"Training Started...\")\n",
    "        for epoch in range(10): # Epoch ìˆ˜ ì¡°ì ˆ\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            \n",
    "            for batch_x, batch_y, batch_mask in train_loader:\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                batch_mask = batch_mask.to(device) # ë§ˆìŠ¤í¬ ì „ë‹¬ í•„ìˆ˜\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # ëª¨ë¸ Forward (ë§ˆìŠ¤í¬ í¬í•¨)\n",
    "                outputs = model(batch_x, batch_mask)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "            \n",
    "        print(\"Training Finished.\")\n",
    "    else:\n",
    "        print(\"ë°ì´í„° íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "def preprocess_ninapro_robust(file_path, target_freq=1000, window_ms=500, overlap_ratio=0.5):\n",
    "    # 1. .mat íŒŒì¼ ë¡œë“œ\n",
    "    try:\n",
    "        mat = scipy.io.loadmat(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    # ë³€ìˆ˜ëª… í™•ì¸ ë° ë°ì´í„° ì¶”ì¶œ\n",
    "    if 'emg' in mat:\n",
    "        emg = mat['emg']\n",
    "    elif 'data' in mat: # ì¼ë¶€ ë°ì´í„°ì…‹ ëŒ€ì‘\n",
    "        emg = mat['data']\n",
    "    else:\n",
    "        print(f\"Key Error: .mat íŒŒì¼ ë‚´ì— 'emg' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. í¬í•¨ëœ í‚¤: {mat.keys()}\")\n",
    "        return None, None\n",
    "        \n",
    "    # ë¼ë²¨ ì¶”ì¶œ (DB5ëŠ”ë³´í†µ 'stimulus' ë˜ëŠ” 'restimulus' ì‚¬ìš©)\n",
    "    if 'stimulus' in mat:\n",
    "        label = mat['stimulus']\n",
    "    elif 'restimulus' in mat:\n",
    "        label = mat['restimulus']\n",
    "    else:\n",
    "        label = np.zeros((emg.shape[0], 1))\n",
    "\n",
    "    # --- [í•µì‹¬ ìˆ˜ì • ì‚¬í•­] ---\n",
    "    # íŒŒì¼ ê²½ë¡œì— 'db5'ê°€ ë³´ì…ë‹ˆë‹¤. Ninapro DB5ëŠ” 200Hzì…ë‹ˆë‹¤.\n",
    "    # ë§Œì•½ DB2ë¼ë©´ 2000, DB1ì´ë¼ë©´ 100, DB5ë¼ë©´ 200ìœ¼ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    if 'db5' in file_path.lower():\n",
    "        original_freq = 200\n",
    "    elif 'db1' in file_path.lower():\n",
    "        original_freq = 100\n",
    "    else:\n",
    "        original_freq = 2000 # ê¸°ë³¸ê°’ (DB2 ë“±)\n",
    "\n",
    "    # 2. í•„í„° ì ìš© (ë™ì  ì¡°ì •)\n",
    "    # Nyquist ì£¼íŒŒìˆ˜ ê³„ì‚° (ìƒ˜í”Œë§ ë ˆì´íŠ¸ì˜ ì ˆë°˜)\n",
    "    nyq = 0.5 * original_freq\n",
    "    \n",
    "    # ëª©í‘œ í•„í„° ì£¼íŒŒìˆ˜\n",
    "    low_cut = 20   # ì›€ì§ì„ ì¡ìŒ ì œê±° (High-pass)\n",
    "    high_cut = 450 # ê³ ì£¼íŒŒ ë…¸ì´ì¦ˆ ì œê±° (Low-pass)\n",
    "    \n",
    "    b, a = None, None\n",
    "    \n",
    "    # í•„í„° ì„¤ê³„ ë¡œì§ ìˆ˜ì •:\n",
    "    # ë°ì´í„°ì˜ í•œê³„(Nyquist)ê°€ 450Hzë³´ë‹¤ ë‚®ìœ¼ë©´ Low-pass í•„í„°ë¥¼ ìƒëµí•˜ê±°ë‚˜ ì¡°ì •í•´ì•¼ í•¨\n",
    "    if nyq > high_cut:\n",
    "        # 2000Hz ë°ì´í„° ë“± ì¶©ë¶„íˆ ê³ í•´ìƒë„ì¼ ë•Œ: Band-pass (20~450Hz)\n",
    "        b, a = signal.butter(4, [low_cut/nyq, high_cut/nyq], btype='band')\n",
    "        emg_filtered = signal.filtfilt(b, a, emg, axis=0)\n",
    "    elif nyq > low_cut:\n",
    "        # 200Hz ë°ì´í„°(Nyq=100)ì¼ ë•Œ: High-pass (20Hz)ë§Œ ì ìš© (450Hz í•„í„°ë§ ë¶ˆê°€)\n",
    "        # 100Hz ì´ìƒ ì„±ë¶„ì€ ì´ë¯¸ ë¬¼ë¦¬ì ìœ¼ë¡œ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ Low-pass ë¶ˆí•„ìš”\n",
    "        b, a = signal.butter(4, low_cut/nyq, btype='high')\n",
    "        emg_filtered = signal.filtfilt(b, a, emg, axis=0)\n",
    "        print(f\"Warning: {original_freq}Hz ë°ì´í„°ë¼ 450Hz í•„í„°ëŠ” ìƒëµí•˜ê³  20Hz High-passë§Œ ì ìš©í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        # 100Hz ì´í•˜ ë°ì´í„° ë“±: í•„í„° ì ìš© ìœ„í—˜í•˜ë¯€ë¡œ ì›ë³¸ ì‚¬ìš© í˜¹ì€ ë‹¨ìˆœ ì •ê·œí™”\n",
    "        emg_filtered = emg\n",
    "        print(\"Warning: ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜ê°€ ë„ˆë¬´ ë‚®ì•„ í•„í„°ë¥¼ ì ìš©í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 3. Resampling (target_freqë¡œ í†µì¼, ì˜ˆ: 1000Hz)\n",
    "    num_samples = int(len(emg_filtered) * target_freq / original_freq)\n",
    "    emg_resampled = signal.resample(emg_filtered, num_samples, axis=0)\n",
    "    label_resampled = signal.resample(label, num_samples, axis=0).round().astype(int)\n",
    "\n",
    "    # 4. Sliding Window ì²˜ë¦¬\n",
    "    window_size = int(target_freq * (window_ms / 1000))\n",
    "    step_size = int(window_size * (1 - overlap_ratio))\n",
    "    \n",
    "    X, Y = [], []\n",
    "    \n",
    "    for i in range(0, len(emg_resampled) - window_size, step_size):\n",
    "        window_data = emg_resampled[i:i+window_size, :] \n",
    "        window_label = label_resampled[i:i+window_size]\n",
    "        \n",
    "        unique, counts = np.unique(window_label, return_counts=True)\n",
    "        final_label = unique[np.argmax(counts)]\n",
    "        \n",
    "        if final_label == 0: continue \n",
    "        \n",
    "        X.append(window_data.T) # (Channel, Time)\n",
    "        Y.append(final_label)\n",
    "        \n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# ì‹¤í–‰ (ê²½ë¡œ í™•ì¸)\n",
    "x_data, y_data = preprocess_ninapro_robust('ninapro_db5/ninapro_db_1/S1_E2_A1.mat')\n",
    "\n",
    "if x_data is not None:\n",
    "    print(f\"\\n--- ì „ì²˜ë¦¬ ê²°ê³¼ ---\")\n",
    "    print(f\"ë°ì´í„° shape: {x_data.shape}\") # (Batch, 16, 500)\n",
    "    print(f\"ë¼ë²¨ shape: {y_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠœí”Œ í˜•íƒœ ì œê±° ë° ìˆ«ìí˜• ë³€í™˜\n",
    "ninapro_df['Restimulus'] = ninapro_df['Restimulus'].apply(lambda x: x[0] if isinstance(x, (list, tuple, np.ndarray)) else x)\n",
    "ninapro_df['rerepetition'] = ninapro_df['rerepetition'].apply(lambda x: x[0] if isinstance(x, (list, tuple, np.ndarray)) else x)\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ë°ì´í„° íƒ€ì… ë³€í™˜ (float32, int8)\n",
    "ninapro_df.iloc[:, :16] = ninapro_df.iloc[:, :16].astype('float32')\n",
    "ninapro_df['Restimulus'] = ninapro_df['Restimulus'].astype('int8')\n",
    "ninapro_df['rerepetition'] = ninapro_df['rerepetition'].astype('int8')\n",
    "\n",
    "def create_windows(data, window_size=40, step_size=20):\n",
    "    \"\"\"\n",
    "    window_size: 200Hz ê¸°ì¤€ 40ìƒ˜í”Œì€ 200msì…ë‹ˆë‹¤.\n",
    "    step_size: ìœˆë„ìš° ê°„ì˜ ê²¹ì¹¨(Overlap) ì •ë„ì…ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # ë°ì´í„° ì¶”ì¶œ (16ê°œ EMG ì»¬ëŸ¼)\n",
    "    emg_data = data.iloc[:, :16].values\n",
    "    labels = data['Restimulus'].values\n",
    "    \n",
    "    for i in range(0, len(data) - window_size, step_size):\n",
    "        window_x = emg_data[i : i + window_size]\n",
    "        # ìœˆë„ìš° ë‚´ì—ì„œ ê°€ì¥ ë§ì´ ë“±ì¥í•œ ë ˆì´ë¸”ì„ í•´ë‹¹ ìœˆë„ìš°ì˜ ì •ë‹µìœ¼ë¡œ ì„ íƒ\n",
    "        window_y = np.bincount(labels[i : i + window_size]).argmax()\n",
    "        \n",
    "        X.append(window_x)\n",
    "        y.append(window_y)\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "# 1. Train / Test ì„¸íŠ¸ ë¶„ë¦¬ (ì˜ˆ: 2, 5íšŒì°¨ë¥¼ Testë¡œ ì‚¬ìš©)\n",
    "test_reps = [2, 5]\n",
    "train_df = ninapro_df[~ninapro_df['rerepetition'].isin(test_reps)]\n",
    "test_df = ninapro_df[ninapro_df['rerepetition'].isin(test_reps)]\n",
    "\n",
    "# 2. ìœˆë„ìš° ë°ì´í„° ìƒì„±\n",
    "# window_size=40 (200ms), step_size=10 (50% overlap ë“± ì„¤ì • ê°€ëŠ¥)\n",
    "X_train, y_train = create_windows(train_df, window_size=40, step_size=10)\n",
    "X_test, y_test = create_windows(test_df, window_size=40, step_size=10)\n",
    "\n",
    "print(f\"Train ë°ì´í„° í˜•íƒœ: {X_train.shape}\") # (ìƒ˜í”Œ ìˆ˜, 40, 16)\n",
    "print(f\"Test ë°ì´í„° í˜•íƒœ: {X_test.shape}\")   # (ìƒ˜í”Œ ìˆ˜, 40, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92993373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# ==========================================\n",
    "# 1. ëª¨ë¸ ì •ì˜ (CPUìš© ê²½ëŸ‰í™” ë²„ì „)\n",
    "# ==========================================\n",
    "class ChannelAgnosticNetwork(nn.Module):\n",
    "    def __init__(self, num_classes, d_model=64, input_channels=16): # d_modelì„ 128->64ë¡œ ì¤„ì„ (ì†ë„ í–¥ìƒ)\n",
    "        super(ChannelAgnosticNetwork, self).__init__()\n",
    "        \n",
    "        # [Stage 1] Shared Encoder \n",
    "        self.shared_encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=11, padding=5), # í•„í„° ìˆ˜ ì¤„ì„\n",
    "            nn.BatchNorm1d(16), nn.ReLU(), nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Conv1d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(32), nn.ReLU(), nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Conv1d(32, d_model, kernel_size=3, padding=1),\n",
    "            nn.AdaptiveAvgPool1d(1), \n",
    "            nn.Flatten()             \n",
    "        )\n",
    "        \n",
    "        # [Stage 2] Attention Mechanism\n",
    "        self.attn_fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3), # Dropout ë‚®ì¶¤\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        B, C, T = x.shape\n",
    "        x_reshaped = x.view(B * C, 1, T)\n",
    "        \n",
    "        features = self.shared_encoder(x_reshaped) \n",
    "        features = features.view(B, C, -1)         \n",
    "        \n",
    "        attn_scores = self.attn_fc(features).squeeze(-1) \n",
    "        \n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "            \n",
    "        attn_weights = torch.softmax(attn_scores, dim=1).unsqueeze(-1) \n",
    "        global_feature = torch.sum(features * attn_weights, dim=1) \n",
    "        \n",
    "        return self.classifier(global_feature)\n",
    "\n",
    "# ==========================================\n",
    "# 2. í•™ìŠµ ì‹¤í–‰ í•¨ìˆ˜ (CPU ìµœì í™”)\n",
    "# ==========================================\n",
    "def train_model_cpu():\n",
    "    # --- CPU ê°•ì œ ì„¤ì • ---\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(f\"âœ… í˜„ì¬ ì„¤ì •ëœ ì¥ì¹˜: {DEVICE} (ê·¸ë˜í”½ì¹´ë“œ ì—†ì´ í•™ìŠµí•©ë‹ˆë‹¤)\")\n",
    "    \n",
    "    # ì„¤ì •ê°’ (CPU ë¶€í•˜ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¡°ì ˆ)\n",
    "    BATCH_SIZE = 32 # 64 -> 32 (ë©”ëª¨ë¦¬ ë¶€ë‹´ ì™„í™”)\n",
    "    LEARNING_RATE = 0.001\n",
    "    EPOCHS = 10     # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 10ìœ¼ë¡œ ì„¤ì •\n",
    "\n",
    "    # --- ë°ì´í„° ë¡œë“œ ---\n",
    "    print(\"ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "    try:\n",
    "        X_all = np.load('x_train.npy')\n",
    "        Y_all = np.load('y_train.npy')\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ ì—ëŸ¬: x_train.npy, y_train.npy íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # ë¼ë²¨ ì¡°ì •\n",
    "    if Y_all.min() > 0:\n",
    "        Y_all = Y_all - 1\n",
    "        \n",
    "    NUM_CLASSES = len(np.unique(Y_all))\n",
    "    print(f\"ğŸ“Š ë°ì´í„° ì •ë³´: {len(X_all)}ê°œ ìƒ˜í”Œ, {NUM_CLASSES}ê°œ í´ë˜ìŠ¤\")\n",
    "\n",
    "    # ë§ˆìŠ¤í¬ ìƒì„±\n",
    "    Mask_all = (np.abs(X_all).sum(axis=2) > 0).astype(np.float32)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_val, y_train, y_val, m_train, m_val = train_test_split(\n",
    "        X_all, Y_all, Mask_all, test_size=0.2, random_state=42, stratify=Y_all\n",
    "    )\n",
    "\n",
    "    # í…ì„œ ë³€í™˜ (CPUì—ì„œëŠ” .to(DEVICE)ë¥¼ ë¯¸ë¦¬ í•˜ì§€ ì•Šê³  DataLoaderì—ì„œ í•¨)\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.FloatTensor(X_train), torch.LongTensor(y_train), torch.FloatTensor(m_train)\n",
    "    )\n",
    "    val_dataset = TensorDataset(\n",
    "        torch.FloatTensor(X_val), torch.LongTensor(y_val), torch.FloatTensor(m_val)\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # ëª¨ë¸ ìƒì„±\n",
    "    model = ChannelAgnosticNetwork(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # --- í•™ìŠµ ë£¨í”„ ---\n",
    "    print(\"\\nğŸš€ í•™ìŠµ ì‹œì‘ (CPU ëª¨ë“œ)...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (x_batch, y_batch, mask_batch) in enumerate(train_loader):\n",
    "            # ë°ì´í„°ë¥¼ CPU ì¥ì¹˜ë¡œ ë³´ëƒ„\n",
    "            x_batch = x_batch.to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE)\n",
    "            mask_batch = mask_batch.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch, mask_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "            \n",
    "            # CPUëŠ” ëŠë¦¬ë¯€ë¡œ ì§„í–‰ìƒí™©ì„ ìì£¼ ë³´ì—¬ì¤Œ\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f\"  [Epoch {epoch+1}] Batch {i+1}/{len(train_loader)} ì§„í–‰ ì¤‘...\", end='\\r')\n",
    "            \n",
    "        train_acc = 100 * correct / total\n",
    "        \n",
    "        # ê²€ì¦\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch, mask_batch in val_loader:\n",
    "                x_batch, y_batch, mask_batch = x_batch.to(DEVICE), y_batch.to(DEVICE), mask_batch.to(DEVICE)\n",
    "                outputs = model(x_batch, mask_batch)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += y_batch.size(0)\n",
    "                val_correct += (predicted == y_batch).sum().item()\n",
    "        \n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nTime: {epoch_time:.0f}s | Epoch [{epoch+1}/{EPOCHS}] \"\n",
    "              f\"Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Acc: {val_acc:.2f}%\")\n",
    "        start_time = time.time() # ì‹œê°„ ì´ˆê¸°í™”\n",
    "\n",
    "    # ëª¨ë¸ ì €ì¥\n",
    "    torch.save(model.state_dict(), \"gesture_model_cpu.pth\")\n",
    "    print(\"\\nğŸ’¾ í•™ìŠµ ì™„ë£Œ. ëª¨ë¸ ì €ì¥ë¨: gesture_model_cpu.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model_cpu()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
