{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34fad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy import signal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ==========================================\n",
    "# 1. 데이터셋 클래스 (전처리 및 마스킹 통합)\n",
    "# ==========================================\n",
    "class IntegratedEMGDataset(Dataset):\n",
    "    def __init__(self, file_paths, target_freq=1000, window_ms=500, target_channels=16):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_paths (list): .mat 파일 경로 리스트\n",
    "            target_freq (int): 통일할 샘플링 주파수 (Hz)\n",
    "            window_ms (int): 윈도우 크기 (ms)\n",
    "            target_channels (int): 최대 채널 수 (보통 16)\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.masks = []\n",
    "        self.window_size = int(target_freq * (window_ms / 1000))\n",
    "        \n",
    "        for fp in file_paths:\n",
    "            self._load_and_process(fp, target_freq, target_channels)\n",
    "\n",
    "    def _load_and_process(self, file_path, target_freq, target_channels):\n",
    "        try:\n",
    "            mat = scipy.io.loadmat(file_path)\n",
    "        except:\n",
    "            print(f\"File load error: {file_path}\")\n",
    "            return\n",
    "\n",
    "        # 1-1. 변수명 매핑 (Ninapro, Kaggle 등 데이터셋 대응)\n",
    "        if 'emg' in mat: raw_emg = mat['emg']\n",
    "        elif 'data' in mat: raw_emg = mat['data'].T # (Ch, Time) -> (Time, Ch)\n",
    "        else: return\n",
    "\n",
    "        if 'stimulus' in mat: raw_label = mat['stimulus']\n",
    "        elif 'restimulus' in mat: raw_label = mat['restimulus']\n",
    "        else: raw_label = np.zeros((raw_emg.shape[0], 1))\n",
    "\n",
    "        # 1-2. 원본 주파수 추정 및 필터링\n",
    "        # 파일명이나 데이터 특성에 따라 분기 (DB5=200Hz, DB2=2000Hz 등)\n",
    "        if 'db5' in file_path.lower(): original_freq = 200\n",
    "        elif 'db1' in file_path.lower(): original_freq = 100\n",
    "        else: original_freq = 2000 # 기본값\n",
    "        \n",
    "        # 필터링 (Nyquist 고려)\n",
    "        nyq = 0.5 * original_freq\n",
    "        if nyq > 450: # 고해상도 데이터\n",
    "            b, a = signal.butter(4, [20/nyq, 450/nyq], btype='band')\n",
    "            emg_filtered = signal.filtfilt(b, a, raw_emg, axis=0)\n",
    "        elif nyq > 20: # 저해상도 데이터 (High-pass only)\n",
    "            b, a = signal.butter(4, 20/nyq, btype='high')\n",
    "            emg_filtered = signal.filtfilt(b, a, raw_emg, axis=0)\n",
    "        else:\n",
    "            emg_filtered = raw_emg\n",
    "\n",
    "        # 1-3. Resampling\n",
    "        num_samples = int(len(emg_filtered) * target_freq / original_freq)\n",
    "        emg_resampled = signal.resample(emg_filtered, num_samples, axis=0)\n",
    "        label_resampled = signal.resample(raw_label, num_samples, axis=0).round().astype(int)\n",
    "\n",
    "        # 정규화 (Standardization)\n",
    "        emg_resampled = (emg_resampled - np.mean(emg_resampled, axis=0)) / (np.std(emg_resampled, axis=0) + 1e-6)\n",
    "\n",
    "        # 1-4. Sliding Window & Zero-Padding\n",
    "        curr_channels = emg_resampled.shape[1]\n",
    "        step = int(self.window_size * 0.5) # 50% overlap\n",
    "\n",
    "        for i in range(0, len(emg_resampled) - self.window_size, step):\n",
    "            window_x = emg_resampled[i:i+self.window_size, :]\n",
    "            window_y = label_resampled[i:i+self.window_size]\n",
    "            \n",
    "            # 라벨 결정 (최빈값)\n",
    "            vals, counts = np.unique(window_y, return_counts=True)\n",
    "            label = vals[np.argmax(counts)]\n",
    "            if label == 0: continue # 휴식(Rest) 제외\n",
    "            \n",
    "            # Padding & Masking\n",
    "            # 입력: (Time, Ch) -> 전치 -> (Ch, Time)\n",
    "            x_tensor = torch.FloatTensor(window_x.T) \n",
    "            \n",
    "            if curr_channels < target_channels:\n",
    "                pad_len = target_channels - curr_channels\n",
    "                padding = torch.zeros(pad_len, self.window_size)\n",
    "                x_padded = torch.cat([x_tensor, padding], dim=0)\n",
    "                mask = torch.cat([torch.ones(curr_channels), torch.zeros(pad_len)], dim=0)\n",
    "            else:\n",
    "                x_padded = x_tensor[:target_channels, :] # 16채널 초과는 자름\n",
    "                mask = torch.ones(target_channels)\n",
    "\n",
    "            self.data.append(x_padded)\n",
    "            self.labels.append(label)\n",
    "            self.masks.append(mask)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Label을 0부터 시작하게 조정 (필요 시)\n",
    "        return self.data[idx], torch.tensor(self.labels[idx], dtype=torch.long) - 1, self.masks[idx]\n",
    "\n",
    "# ==========================================\n",
    "# 2. 모델 아키텍처 (CWE-AP Model)\n",
    "# ==========================================\n",
    "class ChannelAgnosticNetwork(nn.Module):\n",
    "    def __init__(self, num_classes=17, d_model=128, window_size=500):\n",
    "        super(ChannelAgnosticNetwork, self).__init__()\n",
    "        \n",
    "        # [Stage 1] Shared Encoder (1D-CNN)\n",
    "        # 모든 채널이 이 레이어를 공유함\n",
    "        self.shared_encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=15, padding=7),\n",
    "            nn.BatchNorm1d(32), nn.ReLU(), nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Conv1d(64, d_model, kernel_size=3, padding=1),\n",
    "            nn.AdaptiveAvgPool1d(1), # 시간축을 1개로 압축\n",
    "            nn.Flatten()             # (B*C, d_model)\n",
    "        )\n",
    "        \n",
    "        # [Stage 2] Attention Mechanism\n",
    "        self.attn_fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        x: (Batch, 16, 500)\n",
    "        mask: (Batch, 16) - 실제 데이터=1, 패딩=0\n",
    "        \"\"\"\n",
    "        B, C, T = x.shape\n",
    "        \n",
    "        # 1. Reshape for Shared Encoder\n",
    "        # (Batch * Channel, 1, Time)\n",
    "        x_reshaped = x.view(B * C, 1, T)\n",
    "        \n",
    "        # 2. Local Feature Extraction\n",
    "        features = self.shared_encoder(x_reshaped) # (B*C, d_model)\n",
    "        features = features.view(B, C, -1)         # (B, C, d_model)\n",
    "        \n",
    "        # 3. Masked Attention Pooling\n",
    "        # Attention Score 계산\n",
    "        attn_scores = self.attn_fc(features).squeeze(-1) # (B, C)\n",
    "        \n",
    "        # Masking: 패딩된 채널의 점수를 매우 낮게 설정하여 Softmax에서 0이 되게 함\n",
    "        if mask is not None:\n",
    "            mask_bool = (mask == 0) # True where padding exists\n",
    "            attn_scores = attn_scores.masked_fill(mask_bool, -1e9)\n",
    "            \n",
    "        attn_weights = torch.softmax(attn_scores, dim=1).unsqueeze(-1) # (B, C, 1)\n",
    "        \n",
    "        # Weighted Sum (Channel Dimension 통합)\n",
    "        # (B, C, d) * (B, C, 1) -> sum(dim=1) -> (B, d)\n",
    "        global_feature = torch.sum(features * attn_weights, dim=1)\n",
    "        \n",
    "        # 4. Classification\n",
    "        out = self.classifier(global_feature)\n",
    "        return out\n",
    "\n",
    "# ==========================================\n",
    "# 3. 실행 및 학습 루프 예시\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. 데이터 준비 (경로 리스트)\n",
    "    # 실제 존재하는 .mat 파일 경로들을 리스트에 넣으세요.\n",
    "    file_list = [\n",
    "        \"S1_E2_A1.mat\", \n",
    "        # \"Subject2_session1.mat\", \n",
    "        # \"Kaggle_User1.mat\" \n",
    "    ]\n",
    "    \n",
    "    # 파일이 실제로 있을 때만 실행\n",
    "    if os.path.exists(file_list[0]):\n",
    "        dataset = IntegratedEMGDataset(file_list, target_channels=16)\n",
    "        \n",
    "        # Train/Test Split\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        test_size = len(dataset) - train_size\n",
    "        train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        # 2. 모델 초기화\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = ChannelAgnosticNetwork(num_classes=17).to(device) # 클래스 수는 데이터셋에 맞게 조정\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # 3. 학습 루프\n",
    "        print(\"Training Started...\")\n",
    "        for epoch in range(10): # Epoch 수 조절\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            \n",
    "            for batch_x, batch_y, batch_mask in train_loader:\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                batch_mask = batch_mask.to(device) # 마스크 전달 필수\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # 모델 Forward (마스크 포함)\n",
    "                outputs = model(batch_x, batch_mask)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "            \n",
    "        print(\"Training Finished.\")\n",
    "    else:\n",
    "        print(\"데이터 파일 경로를 확인해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "def preprocess_ninapro_robust(file_path, target_freq=1000, window_ms=500, overlap_ratio=0.5):\n",
    "    # 1. .mat 파일 로드\n",
    "    try:\n",
    "        mat = scipy.io.loadmat(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"파일 로드 실패: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    # 변수명 확인 및 데이터 추출\n",
    "    if 'emg' in mat:\n",
    "        emg = mat['emg']\n",
    "    elif 'data' in mat: # 일부 데이터셋 대응\n",
    "        emg = mat['data']\n",
    "    else:\n",
    "        print(f\"Key Error: .mat 파일 내에 'emg' 키가 없습니다. 포함된 키: {mat.keys()}\")\n",
    "        return None, None\n",
    "        \n",
    "    # 라벨 추출 (DB5는보통 'stimulus' 또는 'restimulus' 사용)\n",
    "    if 'stimulus' in mat:\n",
    "        label = mat['stimulus']\n",
    "    elif 'restimulus' in mat:\n",
    "        label = mat['restimulus']\n",
    "    else:\n",
    "        label = np.zeros((emg.shape[0], 1))\n",
    "\n",
    "    # --- [핵심 수정 사항] ---\n",
    "    # 파일 경로에 'db5'가 보입니다. Ninapro DB5는 200Hz입니다.\n",
    "    # 만약 DB2라면 2000, DB1이라면 100, DB5라면 200으로 설정해야 합니다.\n",
    "    if 'db5' in file_path.lower():\n",
    "        original_freq = 200\n",
    "    elif 'db1' in file_path.lower():\n",
    "        original_freq = 100\n",
    "    else:\n",
    "        original_freq = 2000 # 기본값 (DB2 등)\n",
    "\n",
    "    # 2. 필터 적용 (동적 조정)\n",
    "    # Nyquist 주파수 계산 (샘플링 레이트의 절반)\n",
    "    nyq = 0.5 * original_freq\n",
    "    \n",
    "    # 목표 필터 주파수\n",
    "    low_cut = 20   # 움직임 잡음 제거 (High-pass)\n",
    "    high_cut = 450 # 고주파 노이즈 제거 (Low-pass)\n",
    "    \n",
    "    b, a = None, None\n",
    "    \n",
    "    # 필터 설계 로직 수정:\n",
    "    # 데이터의 한계(Nyquist)가 450Hz보다 낮으면 Low-pass 필터를 생략하거나 조정해야 함\n",
    "    if nyq > high_cut:\n",
    "        # 2000Hz 데이터 등 충분히 고해상도일 때: Band-pass (20~450Hz)\n",
    "        b, a = signal.butter(4, [low_cut/nyq, high_cut/nyq], btype='band')\n",
    "        emg_filtered = signal.filtfilt(b, a, emg, axis=0)\n",
    "    elif nyq > low_cut:\n",
    "        # 200Hz 데이터(Nyq=100)일 때: High-pass (20Hz)만 적용 (450Hz 필터링 불가)\n",
    "        # 100Hz 이상 성분은 이미 물리적으로 존재하지 않으므로 Low-pass 불필요\n",
    "        b, a = signal.butter(4, low_cut/nyq, btype='high')\n",
    "        emg_filtered = signal.filtfilt(b, a, emg, axis=0)\n",
    "        print(f\"Warning: {original_freq}Hz 데이터라 450Hz 필터는 생략하고 20Hz High-pass만 적용했습니다.\")\n",
    "    else:\n",
    "        # 100Hz 이하 데이터 등: 필터 적용 위험하므로 원본 사용 혹은 단순 정규화\n",
    "        emg_filtered = emg\n",
    "        print(\"Warning: 샘플링 주파수가 너무 낮아 필터를 적용하지 않았습니다.\")\n",
    "\n",
    "    # 3. Resampling (target_freq로 통일, 예: 1000Hz)\n",
    "    num_samples = int(len(emg_filtered) * target_freq / original_freq)\n",
    "    emg_resampled = signal.resample(emg_filtered, num_samples, axis=0)\n",
    "    label_resampled = signal.resample(label, num_samples, axis=0).round().astype(int)\n",
    "\n",
    "    # 4. Sliding Window 처리\n",
    "    window_size = int(target_freq * (window_ms / 1000))\n",
    "    step_size = int(window_size * (1 - overlap_ratio))\n",
    "    \n",
    "    X, Y = [], []\n",
    "    \n",
    "    for i in range(0, len(emg_resampled) - window_size, step_size):\n",
    "        window_data = emg_resampled[i:i+window_size, :] \n",
    "        window_label = label_resampled[i:i+window_size]\n",
    "        \n",
    "        unique, counts = np.unique(window_label, return_counts=True)\n",
    "        final_label = unique[np.argmax(counts)]\n",
    "        \n",
    "        if final_label == 0: continue \n",
    "        \n",
    "        X.append(window_data.T) # (Channel, Time)\n",
    "        Y.append(final_label)\n",
    "        \n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# 실행 (경로 확인)\n",
    "x_data, y_data = preprocess_ninapro_robust('ninapro_db5/ninapro_db_1/S1_E2_A1.mat')\n",
    "\n",
    "if x_data is not None:\n",
    "    print(f\"\\n--- 전처리 결과 ---\")\n",
    "    print(f\"데이터 shape: {x_data.shape}\") # (Batch, 16, 500)\n",
    "    print(f\"라벨 shape: {y_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜플 형태 제거 및 숫자형 변환\n",
    "ninapro_df['Restimulus'] = ninapro_df['Restimulus'].apply(lambda x: x[0] if isinstance(x, (list, tuple, np.ndarray)) else x)\n",
    "ninapro_df['rerepetition'] = ninapro_df['rerepetition'].apply(lambda x: x[0] if isinstance(x, (list, tuple, np.ndarray)) else x)\n",
    "\n",
    "# 메모리 절약을 위해 데이터 타입 변환 (float32, int8)\n",
    "ninapro_df.iloc[:, :16] = ninapro_df.iloc[:, :16].astype('float32')\n",
    "ninapro_df['Restimulus'] = ninapro_df['Restimulus'].astype('int8')\n",
    "ninapro_df['rerepetition'] = ninapro_df['rerepetition'].astype('int8')\n",
    "\n",
    "def create_windows(data, window_size=40, step_size=20):\n",
    "    \"\"\"\n",
    "    window_size: 200Hz 기준 40샘플은 200ms입니다.\n",
    "    step_size: 윈도우 간의 겹침(Overlap) 정도입니다.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # 데이터 추출 (16개 EMG 컬럼)\n",
    "    emg_data = data.iloc[:, :16].values\n",
    "    labels = data['Restimulus'].values\n",
    "    \n",
    "    for i in range(0, len(data) - window_size, step_size):\n",
    "        window_x = emg_data[i : i + window_size]\n",
    "        # 윈도우 내에서 가장 많이 등장한 레이블을 해당 윈도우의 정답으로 선택\n",
    "        window_y = np.bincount(labels[i : i + window_size]).argmax()\n",
    "        \n",
    "        X.append(window_x)\n",
    "        y.append(window_y)\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "# 1. Train / Test 세트 분리 (예: 2, 5회차를 Test로 사용)\n",
    "test_reps = [2, 5]\n",
    "train_df = ninapro_df[~ninapro_df['rerepetition'].isin(test_reps)]\n",
    "test_df = ninapro_df[ninapro_df['rerepetition'].isin(test_reps)]\n",
    "\n",
    "# 2. 윈도우 데이터 생성\n",
    "# window_size=40 (200ms), step_size=10 (50% overlap 등 설정 가능)\n",
    "X_train, y_train = create_windows(train_df, window_size=40, step_size=10)\n",
    "X_test, y_test = create_windows(test_df, window_size=40, step_size=10)\n",
    "\n",
    "print(f\"Train 데이터 형태: {X_train.shape}\") # (샘플 수, 40, 16)\n",
    "print(f\"Test 데이터 형태: {X_test.shape}\")   # (샘플 수, 40, 16)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
